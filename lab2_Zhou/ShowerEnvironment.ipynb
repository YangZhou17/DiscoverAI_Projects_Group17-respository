{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **Custom Environment for Reinforcement Learning**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The code below is taken from Nicholas Renotte's tutorial on how to create Custom environments for reinforcement learning. [Tutorial](https://youtu.be/Mut_u40Sqz4?t=8940), [code on github](https://github.com/nicknochnack/ReinforcementLearningCourse/blob/main/Project%203%20-%20Custom%20Environment.ipynb).\n",
                "\n",
                "You are encouraged to visit the links above and check out the full code. In this lab, you will practice training a model."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**About the problem**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The task is to build an agent that regulates the shower temperature to give the best shower possible every time.\n",
                "\n",
                "Based the activity of other people in the building, the temperature fluctuates randomly. Assuming that our optimal temperature is between 37 and 39 degrees, we want to train an agent to automatically respond to changes in temperature and get it back within the preferred range.\n",
                "\n",
                "Note that the agent does not know the preffered range ahead of time, and should instead learn the types of adjustments it can make to get a reward."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Import libraries**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "# Avoid reinstalling packages that are available on edstem\n",
                "if not os.getenv(\"ED_COURSE_ID\"):\n",
                "    !pip install tensorflow stable_baselines3 torch collections gym box2d-py --user\n",
                "\n",
                "# Import gym libraries\n",
                "import gym \n",
                "from gym import Env # the supperclass to build our own environment\n",
                "# All different types of spaces available in Gym\n",
                "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
                "\n",
                "# Import helpers\n",
                "import numpy as np\n",
                "import random\n",
                "\n",
                "#Import stable bbaselines libraries\n",
                "from stable_baselines3 import PPO\n",
                "from stable_baselines3.common.vec_env import DummyVecEnv\n",
                "from stable_baselines3.common.evaluation import evaluate_policy"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Inspect types of spaces"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There are four key types of Gym spaces:\n",
                "Box, Discrete, Multibinary and MultiDiscrete.\n",
                "\n",
                "There are two wrapper spaces, Tuple and Dict that help group different spaces together.\n",
                "\n",
                "These spaces can be used to create simple environment, like the shower environment in the following example."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a discrete space\n",
                "disc = Discrete(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "1"
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Sample the discrete space for a value (between 0 and 2)\n",
                "disc.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a box space\n",
                "box = Box(0,1,shape=(3,3))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[0.6619365 , 0.6780284 , 0.97746015],\n       [0.6586716 , 0.4508673 , 0.7846973 ],\n       [0.30040732, 0.3970666 , 0.05371322]], dtype=float32)"
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Sample the box space for a value\n",
                "box.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a tuple space and combine a discrete and box spaces\n",
                "tup = Tuple((Discrete(2), Box(0,100, shape=(1,))))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(1, array([42.377792], dtype=float32))"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Sample the tuple space for a value\n",
                "tup.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a dict space\n",
                "dic = Dict({'height':Discrete(2), \"speed\":Box(0,100, shape=(1,))}).sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a multibinary space\n",
                "multibi = MultiBinary(4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 0, 1, 0], dtype=int8)"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Sample the multibinary space for a value\n",
                "multibi.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a multidiscrete space\n",
                "multidi = MultiDiscrete([5,2,2])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([4, 1, 0])"
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Sample the multidiscrete space for a value\n",
                "multidi.sample()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Create a custom environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a shower environment class with four key functions\n",
                "class ShowerEnv(Env):\n",
                "    # Define a function to initialize the environment\n",
                "    def __init__(self):\n",
                "        # Define the discrete action space: \n",
                "        # Actions we can take, down, hold, up\n",
                "        self.action_space = Discrete(3)\n",
                "        # Define a temperature range from 0 to 100\n",
                "        self.observation_space = Box(low=np.array([0]), high=np.array([100]))\n",
                "        # Set initial state: starting temp is 38 +- 3\n",
                "        self.state = 38 + random.randint(-3,3)\n",
                "        # Set shower length: set to 60 seconds for testing\n",
                "        self.shower_length = 60\n",
                "\n",
                "    # Define the step function for what to do in one action step    \n",
                "    def step(self, action):\n",
                "        # Apply impact of the action on current state\n",
                "        # 0 -1 = -1 temperature\n",
                "        # 1 -1 = 0 \n",
                "        # 2 -1 = 1 temperature \n",
                "        self.state += action -1 \n",
                "        # Reduce shower length by 1 second at each action\n",
                "        self.shower_length -= 1 \n",
                "        \n",
                "        # Calculate reward\n",
                "        # If the temperature is within preferred range, the reward is positive\n",
                "        if self.state \u003e= 37 and self.state \u003c= 39: \n",
                "            reward = 1 \n",
                "        # If the reward is outside of preferred range, the reward is negative \n",
                "        else: \n",
                "            reward = -1 \n",
                "        \n",
                "        # Check if shower is done\n",
                "        if self.shower_length \u003c= 0: \n",
                "            done = True\n",
                "        else:\n",
                "            done = False\n",
                "        \n",
                "        # Set placeholder for info\n",
                "        info = {}\n",
                "        \n",
                "        # Return step information\n",
                "        return self.state, reward, done, info\n",
                "\n",
                "    # For this lab, we will not implement a visualization of the environment\n",
                "    def render(self):\n",
                "        # Implement viz\n",
                "        pass\n",
                "    \n",
                "    # Define function to reset the environment for the next run\n",
                "    def reset(self):\n",
                "        # Reset shower temperature to a random value between 35 and 41\n",
                "        self.state = np.array([38 + random.randint(-3,3)]).astype(float)\n",
                "        # Reset shower time\n",
                "        self.shower_length = 60 \n",
                "        return self.state"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Test the environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/usr/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
                }
            ],
            "source": [
                "# Initialize the environment\n",
                "env=ShowerEnv()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([32.723087], dtype=float32)"
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Write code to sample the environment's observation space\n",
                "env.observation_space.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Write code to sample the environment's action space\n",
                "env.action_space.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([38.])"
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Reset the environment\n",
                "env.reset()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Episode:1 Score:-20\nEpisode:2 Score:-42\nEpisode:3 Score:30\nEpisode:4 Score:-10\nEpisode:5 Score:2\n"
                }
            ],
            "source": [
                "# Test five episodes of taking random Actions\n",
                "# in the environment\n",
                "episodes = 5\n",
                "for episode in range(1, episodes+1):\n",
                "    state = env.reset()\n",
                "    done = False\n",
                "    score = 0 \n",
                "    \n",
                "    while not done:\n",
                "        env.render()\n",
                "        action = env.action_space.sample()\n",
                "        n_state, reward, done, info = env.step(action)\n",
                "        score+=reward\n",
                "    print('Episode:{} Score:{}'.format(episode, score))\n",
                "    \n",
                "env.close()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Earn Your Wings"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Implement the rest of the reinforcement learning algorithm to train the model using MlpPolicy. Save the training in the log_path defined below, and evaluate the model at the end with render set to False. Add comments in your code to explain each step that you take in your implementation.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Using cpu device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\nLogging to ReinforcementLearning/ShowerEnvironment/Training/Logs/PPO_5\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 60       |\n|    ep_rew_mean     | -22.4    |\n| time/              |          |\n|    fps             | 1321     |\n|    iterations      | 1        |\n|    time_elapsed    | 1        |\n|    total_timesteps | 2048     |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -28         |\n| time/                   |             |\n|    fps                  | 1617        |\n|    iterations           | 2           |\n|    time_elapsed         | 2           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.002958261 |\n|    clip_fraction        | 0.00718     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.1        |\n|    explained_variance   | -0.000141   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 33.4        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | 0.000185    |\n|    value_loss           | 58.9        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -29.7       |\n| time/                   |             |\n|    fps                  | 1749        |\n|    iterations           | 3           |\n|    time_elapsed         | 3           |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.007057813 |\n|    clip_fraction        | 0.0203      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.1        |\n|    explained_variance   | 0.00341     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 30.2        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.00179    |\n|    value_loss           | 61.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -31.7       |\n| time/                   |             |\n|    fps                  | 1823        |\n|    iterations           | 4           |\n|    time_elapsed         | 4           |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.012973284 |\n|    clip_fraction        | 0.0548      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.1        |\n|    explained_variance   | -0.00109    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 34.8        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.00547    |\n|    value_loss           | 61.1        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -31.9       |\n| time/                   |             |\n|    fps                  | 1870        |\n|    iterations           | 5           |\n|    time_elapsed         | 5           |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.008458617 |\n|    clip_fraction        | 0.00239     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.1        |\n|    explained_variance   | -7.71e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 38.4        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.000801   |\n|    value_loss           | 72          |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -31.3       |\n| time/                   |             |\n|    fps                  | 1900        |\n|    iterations           | 6           |\n|    time_elapsed         | 6           |\n|    total_timesteps      | 12288       |\n| train/                  |             |\n|    approx_kl            | 0.013974024 |\n|    clip_fraction        | 0.0513      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.1        |\n|    explained_variance   | 1.54e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 35.9        |\n|    n_updates            | 50          |\n|    policy_gradient_loss | -0.00636    |\n|    value_loss           | 61.8        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -32          |\n| time/                   |              |\n|    fps                  | 1926         |\n|    iterations           | 7            |\n|    time_elapsed         | 7            |\n|    total_timesteps      | 14336        |\n| train/                  |              |\n|    approx_kl            | 0.0023751492 |\n|    clip_fraction        | 0.000879     |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.09        |\n|    explained_variance   | -3.99e-05    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 33.2         |\n|    n_updates            | 60           |\n|    policy_gradient_loss | -0.000196    |\n|    value_loss           | 85.7         |\n------------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | -27.8         |\n| time/                   |               |\n|    fps                  | 1946          |\n|    iterations           | 8             |\n|    time_elapsed         | 8             |\n|    total_timesteps      | 16384         |\n| train/                  |               |\n|    approx_kl            | 0.00051566435 |\n|    clip_fraction        | 0.0198        |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.09         |\n|    explained_variance   | -1.66e-05     |\n|    learning_rate        | 0.0003        |\n|    loss                 | 33.7          |\n|    n_updates            | 70            |\n|    policy_gradient_loss | 8.33e-05      |\n|    value_loss           | 71.3          |\n-------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -26.1        |\n| time/                   |              |\n|    fps                  | 1961         |\n|    iterations           | 9            |\n|    time_elapsed         | 9            |\n|    total_timesteps      | 18432        |\n| train/                  |              |\n|    approx_kl            | 0.0048894887 |\n|    clip_fraction        | 0.028        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.1         |\n|    explained_variance   | -7.99e-06    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 30.5         |\n|    n_updates            | 80           |\n|    policy_gradient_loss | -0.0014      |\n|    value_loss           | 60.3         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -28.9       |\n| time/                   |             |\n|    fps                  | 1974        |\n|    iterations           | 10          |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 20480       |\n| train/                  |             |\n|    approx_kl            | 0.009462243 |\n|    clip_fraction        | 0.0231      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.1        |\n|    explained_variance   | -0.000157   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 40.4        |\n|    n_updates            | 90          |\n|    policy_gradient_loss | -0.00165    |\n|    value_loss           | 74.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -31.9       |\n| time/                   |             |\n|    fps                  | 1980        |\n|    iterations           | 11          |\n|    time_elapsed         | 11          |\n|    total_timesteps      | 22528       |\n| train/                  |             |\n|    approx_kl            | 0.012250197 |\n|    clip_fraction        | 0.119       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.1        |\n|    explained_variance   | -3.6e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 31.2        |\n|    n_updates            | 100         |\n|    policy_gradient_loss | -0.0102     |\n|    value_loss           | 72.4        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -31.8       |\n| time/                   |             |\n|    fps                  | 1984        |\n|    iterations           | 12          |\n|    time_elapsed         | 12          |\n|    total_timesteps      | 24576       |\n| train/                  |             |\n|    approx_kl            | 0.009240444 |\n|    clip_fraction        | 0.0757      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.09       |\n|    explained_variance   | 0           |\n|    learning_rate        | 0.0003      |\n|    loss                 | 35.4        |\n|    n_updates            | 110         |\n|    policy_gradient_loss | -0.00542    |\n|    value_loss           | 74.3        |\n-----------------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 60        |\n|    ep_rew_mean          | -26       |\n| time/                   |           |\n|    fps                  | 1993      |\n|    iterations           | 13        |\n|    time_elapsed         | 13        |\n|    total_timesteps      | 26624     |\n| train/                  |           |\n|    approx_kl            | 0.0067488 |\n|    clip_fraction        | 0.052     |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.09     |\n|    explained_variance   | -2.97e-05 |\n|    learning_rate        | 0.0003    |\n|    loss                 | 33.8      |\n|    n_updates            | 120       |\n|    policy_gradient_loss | -0.00322  |\n|    value_loss           | 76        |\n---------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | -24.9         |\n| time/                   |               |\n|    fps                  | 2000          |\n|    iterations           | 14            |\n|    time_elapsed         | 14            |\n|    total_timesteps      | 28672         |\n| train/                  |               |\n|    approx_kl            | 0.00090753054 |\n|    clip_fraction        | 0.0168        |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.09         |\n|    explained_variance   | 0.000717      |\n|    learning_rate        | 0.0003        |\n|    loss                 | 35.7          |\n|    n_updates            | 130           |\n|    policy_gradient_loss | -0.000237     |\n|    value_loss           | 76.4          |\n-------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -22.7        |\n| time/                   |              |\n|    fps                  | 2005         |\n|    iterations           | 15           |\n|    time_elapsed         | 15           |\n|    total_timesteps      | 30720        |\n| train/                  |              |\n|    approx_kl            | 0.0022833948 |\n|    clip_fraction        | 0.025        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.09        |\n|    explained_variance   | 0.00257      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 29.9         |\n|    n_updates            | 140          |\n|    policy_gradient_loss | -0.00269     |\n|    value_loss           | 69.7         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -21.6       |\n| time/                   |             |\n|    fps                  | 2010        |\n|    iterations           | 16          |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 32768       |\n| train/                  |             |\n|    approx_kl            | 0.011760592 |\n|    clip_fraction        | 0.0803      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.07       |\n|    explained_variance   | -0.00302    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 41.2        |\n|    n_updates            | 150         |\n|    policy_gradient_loss | -0.00746    |\n|    value_loss           | 74.1        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -17.9        |\n| time/                   |              |\n|    fps                  | 2012         |\n|    iterations           | 17           |\n|    time_elapsed         | 17           |\n|    total_timesteps      | 34816        |\n| train/                  |              |\n|    approx_kl            | 0.0036452091 |\n|    clip_fraction        | 0.0527       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.06        |\n|    explained_variance   | 0.000213     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 35.1         |\n|    n_updates            | 160          |\n|    policy_gradient_loss | -0.000842    |\n|    value_loss           | 72.7         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -17         |\n| time/                   |             |\n|    fps                  | 2016        |\n|    iterations           | 18          |\n|    time_elapsed         | 18          |\n|    total_timesteps      | 36864       |\n| train/                  |             |\n|    approx_kl            | 0.009556733 |\n|    clip_fraction        | 0.123       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.05       |\n|    explained_variance   | 0.000722    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 33.3        |\n|    n_updates            | 170         |\n|    policy_gradient_loss | -0.00968    |\n|    value_loss           | 59.5        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -14.6        |\n| time/                   |              |\n|    fps                  | 2021         |\n|    iterations           | 19           |\n|    time_elapsed         | 19           |\n|    total_timesteps      | 38912        |\n| train/                  |              |\n|    approx_kl            | 0.0056637935 |\n|    clip_fraction        | 0.0735       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.06        |\n|    explained_variance   | -0.0204      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 42.8         |\n|    n_updates            | 180          |\n|    policy_gradient_loss | -0.00633     |\n|    value_loss           | 77.7         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -9.48        |\n| time/                   |              |\n|    fps                  | 2024         |\n|    iterations           | 20           |\n|    time_elapsed         | 20           |\n|    total_timesteps      | 40960        |\n| train/                  |              |\n|    approx_kl            | 0.0073076943 |\n|    clip_fraction        | 0.0716       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.08        |\n|    explained_variance   | 0.000242     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 23.3         |\n|    n_updates            | 190          |\n|    policy_gradient_loss | -0.00185     |\n|    value_loss           | 57.3         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -6.12       |\n| time/                   |             |\n|    fps                  | 2021        |\n|    iterations           | 21          |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 43008       |\n| train/                  |             |\n|    approx_kl            | 0.010729248 |\n|    clip_fraction        | 0.103       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.07       |\n|    explained_variance   | 0.00392     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 19.2        |\n|    n_updates            | 200         |\n|    policy_gradient_loss | -0.00787    |\n|    value_loss           | 43.1        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -6.36       |\n| time/                   |             |\n|    fps                  | 2006        |\n|    iterations           | 22          |\n|    time_elapsed         | 22          |\n|    total_timesteps      | 45056       |\n| train/                  |             |\n|    approx_kl            | 0.005049675 |\n|    clip_fraction        | 0.0477      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.06       |\n|    explained_variance   | 0.00492     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 24.4        |\n|    n_updates            | 210         |\n|    policy_gradient_loss | -0.00305    |\n|    value_loss           | 48.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -2.78       |\n| time/                   |             |\n|    fps                  | 2004        |\n|    iterations           | 23          |\n|    time_elapsed         | 23          |\n|    total_timesteps      | 47104       |\n| train/                  |             |\n|    approx_kl            | 0.010223331 |\n|    clip_fraction        | 0.141       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.06       |\n|    explained_variance   | -0.0277     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 23.6        |\n|    n_updates            | 220         |\n|    policy_gradient_loss | -0.0127     |\n|    value_loss           | 47.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 1.88        |\n| time/                   |             |\n|    fps                  | 2007        |\n|    iterations           | 24          |\n|    time_elapsed         | 24          |\n|    total_timesteps      | 49152       |\n| train/                  |             |\n|    approx_kl            | 0.010362105 |\n|    clip_fraction        | 0.0952      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.06       |\n|    explained_variance   | 7.61e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 25.8        |\n|    n_updates            | 230         |\n|    policy_gradient_loss | -0.00548    |\n|    value_loss           | 45.5        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 8.58         |\n| time/                   |              |\n|    fps                  | 2008         |\n|    iterations           | 25           |\n|    time_elapsed         | 25           |\n|    total_timesteps      | 51200        |\n| train/                  |              |\n|    approx_kl            | 0.0068633514 |\n|    clip_fraction        | 0.143        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.05        |\n|    explained_variance   | -0.000888    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 27.7         |\n|    n_updates            | 240          |\n|    policy_gradient_loss | -0.0103      |\n|    value_loss           | 43.1         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 13.8        |\n| time/                   |             |\n|    fps                  | 2011        |\n|    iterations           | 26          |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 53248       |\n| train/                  |             |\n|    approx_kl            | 0.008898161 |\n|    clip_fraction        | 0.147       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.04       |\n|    explained_variance   | 0.00068     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 23.7        |\n|    n_updates            | 250         |\n|    policy_gradient_loss | -0.00852    |\n|    value_loss           | 42.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 19.3        |\n| time/                   |             |\n|    fps                  | 2008        |\n|    iterations           | 27          |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 55296       |\n| train/                  |             |\n|    approx_kl            | 0.008287935 |\n|    clip_fraction        | 0.114       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.04       |\n|    explained_variance   | 0.00236     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 10.5        |\n|    n_updates            | 260         |\n|    policy_gradient_loss | -0.00299    |\n|    value_loss           | 29.4        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 21.5        |\n| time/                   |             |\n|    fps                  | 2008        |\n|    iterations           | 28          |\n|    time_elapsed         | 28          |\n|    total_timesteps      | 57344       |\n| train/                  |             |\n|    approx_kl            | 0.014119042 |\n|    clip_fraction        | 0.144       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.03       |\n|    explained_variance   | -0.00351    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 23.5        |\n|    n_updates            | 270         |\n|    policy_gradient_loss | -0.0071     |\n|    value_loss           | 35.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 24.8        |\n| time/                   |             |\n|    fps                  | 2011        |\n|    iterations           | 29          |\n|    time_elapsed         | 29          |\n|    total_timesteps      | 59392       |\n| train/                  |             |\n|    approx_kl            | 0.017430522 |\n|    clip_fraction        | 0.211       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.01       |\n|    explained_variance   | -0.000801   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 27.6        |\n|    n_updates            | 280         |\n|    policy_gradient_loss | -0.0118     |\n|    value_loss           | 41.8        |\n-----------------------------------------\n---------------------------------------\n| rollout/                |           |\n|    ep_len_mean          | 60        |\n|    ep_rew_mean          | 28.5      |\n| time/                   |           |\n|    fps                  | 2013      |\n|    iterations           | 30        |\n|    time_elapsed         | 30        |\n|    total_timesteps      | 61440     |\n| train/                  |           |\n|    approx_kl            | 0.0091797 |\n|    clip_fraction        | 0.165     |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.01     |\n|    explained_variance   | 0.000509  |\n|    learning_rate        | 0.0003    |\n|    loss                 | 15.8      |\n|    n_updates            | 290       |\n|    policy_gradient_loss | -0.00805  |\n|    value_loss           | 40.6      |\n---------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 34.9        |\n| time/                   |             |\n|    fps                  | 2013        |\n|    iterations           | 31          |\n|    time_elapsed         | 31          |\n|    total_timesteps      | 63488       |\n| train/                  |             |\n|    approx_kl            | 0.013734238 |\n|    clip_fraction        | 0.181       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.01       |\n|    explained_variance   | -0.000267   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 22.5        |\n|    n_updates            | 300         |\n|    policy_gradient_loss | 0.00711     |\n|    value_loss           | 41.6        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 32.7       |\n| time/                   |            |\n|    fps                  | 2014       |\n|    iterations           | 32         |\n|    time_elapsed         | 32         |\n|    total_timesteps      | 65536      |\n| train/                  |            |\n|    approx_kl            | 0.01510345 |\n|    clip_fraction        | 0.142      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.999     |\n|    explained_variance   | 5.25e-05   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 19.7       |\n|    n_updates            | 310        |\n|    policy_gradient_loss | 0.00457    |\n|    value_loss           | 47.1       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 34          |\n| time/                   |             |\n|    fps                  | 2015        |\n|    iterations           | 33          |\n|    time_elapsed         | 33          |\n|    total_timesteps      | 67584       |\n| train/                  |             |\n|    approx_kl            | 0.010281832 |\n|    clip_fraction        | 0.19        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.993      |\n|    explained_variance   | -0.000146   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 27.9        |\n|    n_updates            | 320         |\n|    policy_gradient_loss | -0.011      |\n|    value_loss           | 58.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 34.9        |\n| time/                   |             |\n|    fps                  | 2017        |\n|    iterations           | 34          |\n|    time_elapsed         | 34          |\n|    total_timesteps      | 69632       |\n| train/                  |             |\n|    approx_kl            | 0.007851951 |\n|    clip_fraction        | 0.188       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.985      |\n|    explained_variance   | -0.000115   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 23.9        |\n|    n_updates            | 330         |\n|    policy_gradient_loss | 0.00631     |\n|    value_loss           | 46.4        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 41.3        |\n| time/                   |             |\n|    fps                  | 2019        |\n|    iterations           | 35          |\n|    time_elapsed         | 35          |\n|    total_timesteps      | 71680       |\n| train/                  |             |\n|    approx_kl            | 0.006126813 |\n|    clip_fraction        | 0.171       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.98       |\n|    explained_variance   | 4.48e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 30.3        |\n|    n_updates            | 340         |\n|    policy_gradient_loss | 0.00472     |\n|    value_loss           | 53.8        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 41.7        |\n| time/                   |             |\n|    fps                  | 2021        |\n|    iterations           | 36          |\n|    time_elapsed         | 36          |\n|    total_timesteps      | 73728       |\n| train/                  |             |\n|    approx_kl            | 0.021973746 |\n|    clip_fraction        | 0.184       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.987      |\n|    explained_variance   | -1.3e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 18.9        |\n|    n_updates            | 350         |\n|    policy_gradient_loss | 0.00608     |\n|    value_loss           | 63.2        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 43.5         |\n| time/                   |              |\n|    fps                  | 2023         |\n|    iterations           | 37           |\n|    time_elapsed         | 37           |\n|    total_timesteps      | 75776        |\n| train/                  |              |\n|    approx_kl            | 0.0060539553 |\n|    clip_fraction        | 0.198        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.981       |\n|    explained_variance   | 1.68e-05     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 29.4         |\n|    n_updates            | 360          |\n|    policy_gradient_loss | 0.00568      |\n|    value_loss           | 65.4         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 43.3        |\n| time/                   |             |\n|    fps                  | 2021        |\n|    iterations           | 38          |\n|    time_elapsed         | 38          |\n|    total_timesteps      | 77824       |\n| train/                  |             |\n|    approx_kl            | 0.011716088 |\n|    clip_fraction        | 0.214       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.984      |\n|    explained_variance   | 5.66e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 37.6        |\n|    n_updates            | 370         |\n|    policy_gradient_loss | 0.0119      |\n|    value_loss           | 71.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 44.4        |\n| time/                   |             |\n|    fps                  | 2022        |\n|    iterations           | 39          |\n|    time_elapsed         | 39          |\n|    total_timesteps      | 79872       |\n| train/                  |             |\n|    approx_kl            | 0.018688347 |\n|    clip_fraction        | 0.216       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.974      |\n|    explained_variance   | -3.22e-06   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 31.2        |\n|    n_updates            | 380         |\n|    policy_gradient_loss | 0.0105      |\n|    value_loss           | 74          |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 45.5       |\n| time/                   |            |\n|    fps                  | 2024       |\n|    iterations           | 40         |\n|    time_elapsed         | 40         |\n|    total_timesteps      | 81920      |\n| train/                  |            |\n|    approx_kl            | 0.01141254 |\n|    clip_fraction        | 0.181      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.972     |\n|    explained_variance   | -1.29e-05  |\n|    learning_rate        | 0.0003     |\n|    loss                 | 40.7       |\n|    n_updates            | 390        |\n|    policy_gradient_loss | 0.00517    |\n|    value_loss           | 74.3       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 44.7        |\n| time/                   |             |\n|    fps                  | 2025        |\n|    iterations           | 41          |\n|    time_elapsed         | 41          |\n|    total_timesteps      | 83968       |\n| train/                  |             |\n|    approx_kl            | 0.011306037 |\n|    clip_fraction        | 0.182       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.982      |\n|    explained_variance   | 3.7e-06     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 41.7        |\n|    n_updates            | 400         |\n|    policy_gradient_loss | 0.00522     |\n|    value_loss           | 76.4        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 46.8        |\n| time/                   |             |\n|    fps                  | 2026        |\n|    iterations           | 42          |\n|    time_elapsed         | 42          |\n|    total_timesteps      | 86016       |\n| train/                  |             |\n|    approx_kl            | 0.010747954 |\n|    clip_fraction        | 0.157       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.963      |\n|    explained_variance   | 4.17e-07    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 44.7        |\n|    n_updates            | 410         |\n|    policy_gradient_loss | 0.00522     |\n|    value_loss           | 71.3        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 43.5        |\n| time/                   |             |\n|    fps                  | 2026        |\n|    iterations           | 43          |\n|    time_elapsed         | 43          |\n|    total_timesteps      | 88064       |\n| train/                  |             |\n|    approx_kl            | 0.024149558 |\n|    clip_fraction        | 0.252       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.951      |\n|    explained_variance   | -1.91e-06   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 39.1        |\n|    n_updates            | 420         |\n|    policy_gradient_loss | 0.015       |\n|    value_loss           | 78.6        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 43.7       |\n| time/                   |            |\n|    fps                  | 2028       |\n|    iterations           | 44         |\n|    time_elapsed         | 44         |\n|    total_timesteps      | 90112      |\n| train/                  |            |\n|    approx_kl            | 0.02446495 |\n|    clip_fraction        | 0.212      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.958     |\n|    explained_variance   | 1.03e-05   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 33.2       |\n|    n_updates            | 430        |\n|    policy_gradient_loss | 0.000932   |\n|    value_loss           | 85         |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 41.3        |\n| time/                   |             |\n|    fps                  | 2029        |\n|    iterations           | 45          |\n|    time_elapsed         | 45          |\n|    total_timesteps      | 92160       |\n| train/                  |             |\n|    approx_kl            | 0.024137406 |\n|    clip_fraction        | 0.255       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.955      |\n|    explained_variance   | 8.76e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 32.8        |\n|    n_updates            | 440         |\n|    policy_gradient_loss | 0.0102      |\n|    value_loss           | 71.4        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 45.2        |\n| time/                   |             |\n|    fps                  | 2030        |\n|    iterations           | 46          |\n|    time_elapsed         | 46          |\n|    total_timesteps      | 94208       |\n| train/                  |             |\n|    approx_kl            | 0.014671092 |\n|    clip_fraction        | 0.201       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.958      |\n|    explained_variance   | 1.13e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 32.4        |\n|    n_updates            | 450         |\n|    policy_gradient_loss | 0.00803     |\n|    value_loss           | 67.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 47.2        |\n| time/                   |             |\n|    fps                  | 2031        |\n|    iterations           | 47          |\n|    time_elapsed         | 47          |\n|    total_timesteps      | 96256       |\n| train/                  |             |\n|    approx_kl            | 0.011640625 |\n|    clip_fraction        | 0.222       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.952      |\n|    explained_variance   | -3.58e-06   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 41.1        |\n|    n_updates            | 460         |\n|    policy_gradient_loss | 0.0133      |\n|    value_loss           | 80.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 49.6        |\n| time/                   |             |\n|    fps                  | 2031        |\n|    iterations           | 48          |\n|    time_elapsed         | 48          |\n|    total_timesteps      | 98304       |\n| train/                  |             |\n|    approx_kl            | 0.021261059 |\n|    clip_fraction        | 0.236       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.942      |\n|    explained_variance   | -3.1e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 45.2        |\n|    n_updates            | 470         |\n|    policy_gradient_loss | 0.0149      |\n|    value_loss           | 82.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 49.2        |\n| time/                   |             |\n|    fps                  | 2032        |\n|    iterations           | 49          |\n|    time_elapsed         | 49          |\n|    total_timesteps      | 100352      |\n| train/                  |             |\n|    approx_kl            | 0.028292347 |\n|    clip_fraction        | 0.275       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.926      |\n|    explained_variance   | 4.59e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 42.5        |\n|    n_updates            | 480         |\n|    policy_gradient_loss | 0.0146      |\n|    value_loss           | 88.4        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 48.4       |\n| time/                   |            |\n|    fps                  | 2033       |\n|    iterations           | 50         |\n|    time_elapsed         | 50         |\n|    total_timesteps      | 102400     |\n| train/                  |            |\n|    approx_kl            | 0.01607689 |\n|    clip_fraction        | 0.159      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.934     |\n|    explained_variance   | -1.55e-06  |\n|    learning_rate        | 0.0003     |\n|    loss                 | 42.7       |\n|    n_updates            | 490        |\n|    policy_gradient_loss | 0.00656    |\n|    value_loss           | 85.2       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 46          |\n| time/                   |             |\n|    fps                  | 2035        |\n|    iterations           | 51          |\n|    time_elapsed         | 51          |\n|    total_timesteps      | 104448      |\n| train/                  |             |\n|    approx_kl            | 0.011344846 |\n|    clip_fraction        | 0.22        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.933      |\n|    explained_variance   | 1.19e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 32          |\n|    n_updates            | 500         |\n|    policy_gradient_loss | 0.00723     |\n|    value_loss           | 85.3        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 41.4        |\n| time/                   |             |\n|    fps                  | 2036        |\n|    iterations           | 52          |\n|    time_elapsed         | 52          |\n|    total_timesteps      | 106496      |\n| train/                  |             |\n|    approx_kl            | 0.025935432 |\n|    clip_fraction        | 0.207       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.942      |\n|    explained_variance   | 5.25e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 40.6        |\n|    n_updates            | 510         |\n|    policy_gradient_loss | 0.00372     |\n|    value_loss           | 87.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 43          |\n| time/                   |             |\n|    fps                  | 2037        |\n|    iterations           | 53          |\n|    time_elapsed         | 53          |\n|    total_timesteps      | 108544      |\n| train/                  |             |\n|    approx_kl            | 0.014519075 |\n|    clip_fraction        | 0.209       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.927      |\n|    explained_variance   | 9e-06       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 36.6        |\n|    n_updates            | 520         |\n|    policy_gradient_loss | 0.00069     |\n|    value_loss           | 75.9        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 45.5         |\n| time/                   |              |\n|    fps                  | 2037         |\n|    iterations           | 54           |\n|    time_elapsed         | 54           |\n|    total_timesteps      | 110592       |\n| train/                  |              |\n|    approx_kl            | 0.0073805293 |\n|    clip_fraction        | 0.186        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.929       |\n|    explained_variance   | 0.000275     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 41.7         |\n|    n_updates            | 530          |\n|    policy_gradient_loss | 0.00512      |\n|    value_loss           | 78.3         |\n------------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 51.7       |\n| time/                   |            |\n|    fps                  | 2038       |\n|    iterations           | 55         |\n|    time_elapsed         | 55         |\n|    total_timesteps      | 112640     |\n| train/                  |            |\n|    approx_kl            | 0.02072805 |\n|    clip_fraction        | 0.207      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.929     |\n|    explained_variance   | 3.24e-05   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 40.5       |\n|    n_updates            | 540        |\n|    policy_gradient_loss | 0.00714    |\n|    value_loss           | 81.3       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 53.2        |\n| time/                   |             |\n|    fps                  | 2039        |\n|    iterations           | 56          |\n|    time_elapsed         | 56          |\n|    total_timesteps      | 114688      |\n| train/                  |             |\n|    approx_kl            | 0.011137824 |\n|    clip_fraction        | 0.203       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.931      |\n|    explained_variance   | 5.6e-06     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 64.1        |\n|    n_updates            | 550         |\n|    policy_gradient_loss | 0.0113      |\n|    value_loss           | 88.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 54.2        |\n| time/                   |             |\n|    fps                  | 2040        |\n|    iterations           | 57          |\n|    time_elapsed         | 57          |\n|    total_timesteps      | 116736      |\n| train/                  |             |\n|    approx_kl            | 0.019139145 |\n|    clip_fraction        | 0.29        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.925      |\n|    explained_variance   | 1.91e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 42.7        |\n|    n_updates            | 560         |\n|    policy_gradient_loss | 0.0161      |\n|    value_loss           | 93.4        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 53.8        |\n| time/                   |             |\n|    fps                  | 2041        |\n|    iterations           | 58          |\n|    time_elapsed         | 58          |\n|    total_timesteps      | 118784      |\n| train/                  |             |\n|    approx_kl            | 0.016156489 |\n|    clip_fraction        | 0.207       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.918      |\n|    explained_variance   | 5.36e-07    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 38          |\n|    n_updates            | 570         |\n|    policy_gradient_loss | 0.0107      |\n|    value_loss           | 98.7        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 51.5       |\n| time/                   |            |\n|    fps                  | 2041       |\n|    iterations           | 59         |\n|    time_elapsed         | 59         |\n|    total_timesteps      | 120832     |\n| train/                  |            |\n|    approx_kl            | 0.02752932 |\n|    clip_fraction        | 0.217      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.874     |\n|    explained_variance   | -1.19e-07  |\n|    learning_rate        | 0.0003     |\n|    loss                 | 47.3       |\n|    n_updates            | 580        |\n|    policy_gradient_loss | 0.0126     |\n|    value_loss           | 102        |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 51          |\n| time/                   |             |\n|    fps                  | 2041        |\n|    iterations           | 60          |\n|    time_elapsed         | 60          |\n|    total_timesteps      | 122880      |\n| train/                  |             |\n|    approx_kl            | 0.006838884 |\n|    clip_fraction        | 0.151       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.871      |\n|    explained_variance   | -3.81e-06   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 48.7        |\n|    n_updates            | 590         |\n|    policy_gradient_loss | 0.00532     |\n|    value_loss           | 100         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 51.4        |\n| time/                   |             |\n|    fps                  | 2042        |\n|    iterations           | 61          |\n|    time_elapsed         | 61          |\n|    total_timesteps      | 124928      |\n| train/                  |             |\n|    approx_kl            | 0.022925423 |\n|    clip_fraction        | 0.178       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.872      |\n|    explained_variance   | -3.58e-06   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 69.8        |\n|    n_updates            | 600         |\n|    policy_gradient_loss | 0.0091      |\n|    value_loss           | 97.6        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 51.6       |\n| time/                   |            |\n|    fps                  | 2043       |\n|    iterations           | 62         |\n|    time_elapsed         | 62         |\n|    total_timesteps      | 126976     |\n| train/                  |            |\n|    approx_kl            | 0.01164406 |\n|    clip_fraction        | 0.238      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.861     |\n|    explained_variance   | -1.67e-06  |\n|    learning_rate        | 0.0003     |\n|    loss                 | 50.3       |\n|    n_updates            | 610        |\n|    policy_gradient_loss | 0.0162     |\n|    value_loss           | 99.8       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 51.6        |\n| time/                   |             |\n|    fps                  | 2044        |\n|    iterations           | 63          |\n|    time_elapsed         | 63          |\n|    total_timesteps      | 129024      |\n| train/                  |             |\n|    approx_kl            | 0.049215972 |\n|    clip_fraction        | 0.218       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.852      |\n|    explained_variance   | -2.03e-06   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 32.9        |\n|    n_updates            | 620         |\n|    policy_gradient_loss | 0.0123      |\n|    value_loss           | 98.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 49.8        |\n| time/                   |             |\n|    fps                  | 2044        |\n|    iterations           | 64          |\n|    time_elapsed         | 64          |\n|    total_timesteps      | 131072      |\n| train/                  |             |\n|    approx_kl            | 0.012674512 |\n|    clip_fraction        | 0.206       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.841      |\n|    explained_variance   | -3.58e-06   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 51.2        |\n|    n_updates            | 630         |\n|    policy_gradient_loss | 0.0119      |\n|    value_loss           | 99.5        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 47.8       |\n| time/                   |            |\n|    fps                  | 2043       |\n|    iterations           | 65         |\n|    time_elapsed         | 65         |\n|    total_timesteps      | 133120     |\n| train/                  |            |\n|    approx_kl            | 0.01787604 |\n|    clip_fraction        | 0.149      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.838     |\n|    explained_variance   | -4.89e-06  |\n|    learning_rate        | 0.0003     |\n|    loss                 | 58.4       |\n|    n_updates            | 640        |\n|    policy_gradient_loss | 0.00297    |\n|    value_loss           | 97.2       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 45          |\n| time/                   |             |\n|    fps                  | 2044        |\n|    iterations           | 66          |\n|    time_elapsed         | 66          |\n|    total_timesteps      | 135168      |\n| train/                  |             |\n|    approx_kl            | 0.014844639 |\n|    clip_fraction        | 0.198       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.825      |\n|    explained_variance   | -9.3e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 47.7        |\n|    n_updates            | 650         |\n|    policy_gradient_loss | 0.00847     |\n|    value_loss           | 89.6        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 36.3         |\n| time/                   |              |\n|    fps                  | 2045         |\n|    iterations           | 67           |\n|    time_elapsed         | 67           |\n|    total_timesteps      | 137216       |\n| train/                  |              |\n|    approx_kl            | 0.0084237065 |\n|    clip_fraction        | 0.159        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.802       |\n|    explained_variance   | -2.43e-05    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 26           |\n|    n_updates            | 660          |\n|    policy_gradient_loss | 0.0041       |\n|    value_loss           | 85.2         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 30.1        |\n| time/                   |             |\n|    fps                  | 2045        |\n|    iterations           | 68          |\n|    time_elapsed         | 68          |\n|    total_timesteps      | 139264      |\n| train/                  |             |\n|    approx_kl            | 0.017025525 |\n|    clip_fraction        | 0.174       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.785      |\n|    explained_variance   | -3.52e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 36.9        |\n|    n_updates            | 670         |\n|    policy_gradient_loss | -0.00382    |\n|    value_loss           | 71          |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 30.2        |\n| time/                   |             |\n|    fps                  | 2046        |\n|    iterations           | 69          |\n|    time_elapsed         | 69          |\n|    total_timesteps      | 141312      |\n| train/                  |             |\n|    approx_kl            | 0.009260563 |\n|    clip_fraction        | 0.203       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.795      |\n|    explained_variance   | -0.000107   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 22.5        |\n|    n_updates            | 680         |\n|    policy_gradient_loss | -0.0028     |\n|    value_loss           | 58.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 38.8        |\n| time/                   |             |\n|    fps                  | 2046        |\n|    iterations           | 70          |\n|    time_elapsed         | 70          |\n|    total_timesteps      | 143360      |\n| train/                  |             |\n|    approx_kl            | 0.006877033 |\n|    clip_fraction        | 0.166       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.782      |\n|    explained_variance   | 0.000258    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 30.8        |\n|    n_updates            | 690         |\n|    policy_gradient_loss | 0.00468     |\n|    value_loss           | 54.9        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 43.3        |\n| time/                   |             |\n|    fps                  | 2046        |\n|    iterations           | 71          |\n|    time_elapsed         | 71          |\n|    total_timesteps      | 145408      |\n| train/                  |             |\n|    approx_kl            | 0.041654628 |\n|    clip_fraction        | 0.17        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.772      |\n|    explained_variance   | 0.000277    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 49.3        |\n|    n_updates            | 700         |\n|    policy_gradient_loss | 0.00494     |\n|    value_loss           | 66.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 46.9        |\n| time/                   |             |\n|    fps                  | 2045        |\n|    iterations           | 72          |\n|    time_elapsed         | 72          |\n|    total_timesteps      | 147456      |\n| train/                  |             |\n|    approx_kl            | 0.019801596 |\n|    clip_fraction        | 0.17        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.759      |\n|    explained_variance   | 0.000212    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 40.2        |\n|    n_updates            | 710         |\n|    policy_gradient_loss | 0.00011     |\n|    value_loss           | 73          |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 49.2        |\n| time/                   |             |\n|    fps                  | 2045        |\n|    iterations           | 73          |\n|    time_elapsed         | 73          |\n|    total_timesteps      | 149504      |\n| train/                  |             |\n|    approx_kl            | 0.009192473 |\n|    clip_fraction        | 0.186       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.758      |\n|    explained_variance   | 0.000226    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 34.1        |\n|    n_updates            | 720         |\n|    policy_gradient_loss | 0.00991     |\n|    value_loss           | 73.5        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 54.6       |\n| time/                   |            |\n|    fps                  | 2042       |\n|    iterations           | 74         |\n|    time_elapsed         | 74         |\n|    total_timesteps      | 151552     |\n| train/                  |            |\n|    approx_kl            | 0.03141364 |\n|    clip_fraction        | 0.202      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.745     |\n|    explained_variance   | 7.75e-07   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 45         |\n|    n_updates            | 730        |\n|    policy_gradient_loss | 0.014      |\n|    value_loss           | 87.6       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 49.6        |\n| time/                   |             |\n|    fps                  | 2042        |\n|    iterations           | 75          |\n|    time_elapsed         | 75          |\n|    total_timesteps      | 153600      |\n| train/                  |             |\n|    approx_kl            | 0.017130524 |\n|    clip_fraction        | 0.187       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.723      |\n|    explained_variance   | -6.2e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 51.6        |\n|    n_updates            | 740         |\n|    policy_gradient_loss | 0.0119      |\n|    value_loss           | 95.8        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 42.9        |\n| time/                   |             |\n|    fps                  | 2043        |\n|    iterations           | 76          |\n|    time_elapsed         | 76          |\n|    total_timesteps      | 155648      |\n| train/                  |             |\n|    approx_kl            | 0.021973424 |\n|    clip_fraction        | 0.177       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.715      |\n|    explained_variance   | -1.78e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 50          |\n|    n_updates            | 750         |\n|    policy_gradient_loss | 0.00114     |\n|    value_loss           | 103         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 40.7        |\n| time/                   |             |\n|    fps                  | 2044        |\n|    iterations           | 77          |\n|    time_elapsed         | 77          |\n|    total_timesteps      | 157696      |\n| train/                  |             |\n|    approx_kl            | 0.021724863 |\n|    clip_fraction        | 0.164       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.691      |\n|    explained_variance   | 0.000606    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 38.2        |\n|    n_updates            | 760         |\n|    policy_gradient_loss | -0.00194    |\n|    value_loss           | 83.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 43.5        |\n| time/                   |             |\n|    fps                  | 2044        |\n|    iterations           | 78          |\n|    time_elapsed         | 78          |\n|    total_timesteps      | 159744      |\n| train/                  |             |\n|    approx_kl            | 0.044475205 |\n|    clip_fraction        | 0.152       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.679      |\n|    explained_variance   | 0.000404    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 29          |\n|    n_updates            | 770         |\n|    policy_gradient_loss | 0.0109      |\n|    value_loss           | 72          |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 49.6        |\n| time/                   |             |\n|    fps                  | 2045        |\n|    iterations           | 79          |\n|    time_elapsed         | 79          |\n|    total_timesteps      | 161792      |\n| train/                  |             |\n|    approx_kl            | 0.013630504 |\n|    clip_fraction        | 0.152       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.649      |\n|    explained_variance   | 0.000922    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 45.8        |\n|    n_updates            | 780         |\n|    policy_gradient_loss | 0.00294     |\n|    value_loss           | 87.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 52.1        |\n| time/                   |             |\n|    fps                  | 2044        |\n|    iterations           | 80          |\n|    time_elapsed         | 80          |\n|    total_timesteps      | 163840      |\n| train/                  |             |\n|    approx_kl            | 0.019917559 |\n|    clip_fraction        | 0.123       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.656      |\n|    explained_variance   | 0.000727    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 56.7        |\n|    n_updates            | 790         |\n|    policy_gradient_loss | 0.00627     |\n|    value_loss           | 87.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 55.1        |\n| time/                   |             |\n|    fps                  | 2044        |\n|    iterations           | 81          |\n|    time_elapsed         | 81          |\n|    total_timesteps      | 165888      |\n| train/                  |             |\n|    approx_kl            | 0.013816814 |\n|    clip_fraction        | 0.17        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.661      |\n|    explained_variance   | -0.000139   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 35.4        |\n|    n_updates            | 800         |\n|    policy_gradient_loss | 0.0137      |\n|    value_loss           | 93.9        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 56.3        |\n| time/                   |             |\n|    fps                  | 2044        |\n|    iterations           | 82          |\n|    time_elapsed         | 82          |\n|    total_timesteps      | 167936      |\n| train/                  |             |\n|    approx_kl            | 0.012275602 |\n|    clip_fraction        | 0.156       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.663      |\n|    explained_variance   | -9.54e-07   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 46.9        |\n|    n_updates            | 810         |\n|    policy_gradient_loss | 0.0136      |\n|    value_loss           | 102         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 56.2        |\n| time/                   |             |\n|    fps                  | 2044        |\n|    iterations           | 83          |\n|    time_elapsed         | 83          |\n|    total_timesteps      | 169984      |\n| train/                  |             |\n|    approx_kl            | 0.057875384 |\n|    clip_fraction        | 0.134       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.637      |\n|    explained_variance   | -1.19e-07   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 40.3        |\n|    n_updates            | 820         |\n|    policy_gradient_loss | 0.0104      |\n|    value_loss           | 108         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 54.1        |\n| time/                   |             |\n|    fps                  | 2043        |\n|    iterations           | 84          |\n|    time_elapsed         | 84          |\n|    total_timesteps      | 172032      |\n| train/                  |             |\n|    approx_kl            | 0.009788435 |\n|    clip_fraction        | 0.154       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.662      |\n|    explained_variance   | -8.34e-07   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 69.3        |\n|    n_updates            | 830         |\n|    policy_gradient_loss | 0.012       |\n|    value_loss           | 112         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 53.2         |\n| time/                   |              |\n|    fps                  | 2042         |\n|    iterations           | 85           |\n|    time_elapsed         | 85           |\n|    total_timesteps      | 174080       |\n| train/                  |              |\n|    approx_kl            | 0.0068754125 |\n|    clip_fraction        | 0.116        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.649       |\n|    explained_variance   | -6.2e-06     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 42.4         |\n|    n_updates            | 840          |\n|    policy_gradient_loss | 0.000123     |\n|    value_loss           | 113          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 48.8        |\n| time/                   |             |\n|    fps                  | 2040        |\n|    iterations           | 86          |\n|    time_elapsed         | 86          |\n|    total_timesteps      | 176128      |\n| train/                  |             |\n|    approx_kl            | 0.018918209 |\n|    clip_fraction        | 0.129       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.65       |\n|    explained_variance   | -3.46e-06   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 52.4        |\n|    n_updates            | 850         |\n|    policy_gradient_loss | 0.0104      |\n|    value_loss           | 105         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 46.2        |\n| time/                   |             |\n|    fps                  | 2039        |\n|    iterations           | 87          |\n|    time_elapsed         | 87          |\n|    total_timesteps      | 178176      |\n| train/                  |             |\n|    approx_kl            | 0.012825606 |\n|    clip_fraction        | 0.127       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.605      |\n|    explained_variance   | 3.76e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 54.2        |\n|    n_updates            | 860         |\n|    policy_gradient_loss | 0.00314     |\n|    value_loss           | 110         |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 36.7       |\n| time/                   |            |\n|    fps                  | 2039       |\n|    iterations           | 88         |\n|    time_elapsed         | 88         |\n|    total_timesteps      | 180224     |\n| train/                  |            |\n|    approx_kl            | 0.02625826 |\n|    clip_fraction        | 0.136      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.594     |\n|    explained_variance   | 0.000697   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 47.7       |\n|    n_updates            | 870        |\n|    policy_gradient_loss | 0.00301    |\n|    value_loss           | 93.4       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 28.9        |\n| time/                   |             |\n|    fps                  | 2039        |\n|    iterations           | 89          |\n|    time_elapsed         | 89          |\n|    total_timesteps      | 182272      |\n| train/                  |             |\n|    approx_kl            | 0.022087608 |\n|    clip_fraction        | 0.146       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.558      |\n|    explained_variance   | 0.00183     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 33.4        |\n|    n_updates            | 880         |\n|    policy_gradient_loss | -0.00137    |\n|    value_loss           | 88.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 18.9        |\n| time/                   |             |\n|    fps                  | 2039        |\n|    iterations           | 90          |\n|    time_elapsed         | 90          |\n|    total_timesteps      | 184320      |\n| train/                  |             |\n|    approx_kl            | 0.034616686 |\n|    clip_fraction        | 0.188       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.571      |\n|    explained_variance   | 0.0026      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 33.7        |\n|    n_updates            | 890         |\n|    policy_gradient_loss | -0.00618    |\n|    value_loss           | 78.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 27.3        |\n| time/                   |             |\n|    fps                  | 2039        |\n|    iterations           | 91          |\n|    time_elapsed         | 91          |\n|    total_timesteps      | 186368      |\n| train/                  |             |\n|    approx_kl            | 0.053372186 |\n|    clip_fraction        | 0.22        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.57       |\n|    explained_variance   | 0.00373     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 25.6        |\n|    n_updates            | 900         |\n|    policy_gradient_loss | -0.0129     |\n|    value_loss           | 58.3        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 38.3       |\n| time/                   |            |\n|    fps                  | 2039       |\n|    iterations           | 92         |\n|    time_elapsed         | 92         |\n|    total_timesteps      | 188416     |\n| train/                  |            |\n|    approx_kl            | 0.03229208 |\n|    clip_fraction        | 0.124      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.543     |\n|    explained_variance   | 0.00128    |\n|    learning_rate        | 0.0003     |\n|    loss                 | 23.4       |\n|    n_updates            | 910        |\n|    policy_gradient_loss | 0.00916    |\n|    value_loss           | 47.9       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 52.6        |\n| time/                   |             |\n|    fps                  | 2039        |\n|    iterations           | 93          |\n|    time_elapsed         | 93          |\n|    total_timesteps      | 190464      |\n| train/                  |             |\n|    approx_kl            | 0.009341495 |\n|    clip_fraction        | 0.122       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.514      |\n|    explained_variance   | 0.00132     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 30.5        |\n|    n_updates            | 920         |\n|    policy_gradient_loss | 0.0058      |\n|    value_loss           | 62.8        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 55.1        |\n| time/                   |             |\n|    fps                  | 2040        |\n|    iterations           | 94          |\n|    time_elapsed         | 94          |\n|    total_timesteps      | 192512      |\n| train/                  |             |\n|    approx_kl            | 0.013480957 |\n|    clip_fraction        | 0.114       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.492      |\n|    explained_variance   | 0.00126     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 30.8        |\n|    n_updates            | 930         |\n|    policy_gradient_loss | 0.00852     |\n|    value_loss           | 77.8        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 56.6        |\n| time/                   |             |\n|    fps                  | 2040        |\n|    iterations           | 95          |\n|    time_elapsed         | 95          |\n|    total_timesteps      | 194560      |\n| train/                  |             |\n|    approx_kl            | 0.014237272 |\n|    clip_fraction        | 0.117       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.503      |\n|    explained_variance   | -3.86e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 51.5        |\n|    n_updates            | 940         |\n|    policy_gradient_loss | 0.0113      |\n|    value_loss           | 90.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 56.7        |\n| time/                   |             |\n|    fps                  | 2040        |\n|    iterations           | 96          |\n|    time_elapsed         | 96          |\n|    total_timesteps      | 196608      |\n| train/                  |             |\n|    approx_kl            | 0.011674968 |\n|    clip_fraction        | 0.112       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.433      |\n|    explained_variance   | -5.26e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 51.9        |\n|    n_updates            | 950         |\n|    policy_gradient_loss | 0.0141      |\n|    value_loss           | 102         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 57          |\n| time/                   |             |\n|    fps                  | 2041        |\n|    iterations           | 97          |\n|    time_elapsed         | 97          |\n|    total_timesteps      | 198656      |\n| train/                  |             |\n|    approx_kl            | 0.028518809 |\n|    clip_fraction        | 0.114       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.434      |\n|    explained_variance   | 3.06e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 63.8        |\n|    n_updates            | 960         |\n|    policy_gradient_loss | 0.0127      |\n|    value_loss           | 107         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 56.6         |\n| time/                   |              |\n|    fps                  | 2041         |\n|    iterations           | 98           |\n|    time_elapsed         | 98           |\n|    total_timesteps      | 200704       |\n| train/                  |              |\n|    approx_kl            | 0.0075796153 |\n|    clip_fraction        | 0.0796       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.439       |\n|    explained_variance   | 1.19e-05     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 69.1         |\n|    n_updates            | 970          |\n|    policy_gradient_loss | 0.00651      |\n|    value_loss           | 112          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 55.7        |\n| time/                   |             |\n|    fps                  | 2041        |\n|    iterations           | 99          |\n|    time_elapsed         | 99          |\n|    total_timesteps      | 202752      |\n| train/                  |             |\n|    approx_kl            | 0.002611773 |\n|    clip_fraction        | 0.108       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.467      |\n|    explained_variance   | 7.51e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 59.8        |\n|    n_updates            | 980         |\n|    policy_gradient_loss | 0.0128      |\n|    value_loss           | 115         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 54.2        |\n| time/                   |             |\n|    fps                  | 2042        |\n|    iterations           | 100         |\n|    time_elapsed         | 100         |\n|    total_timesteps      | 204800      |\n| train/                  |             |\n|    approx_kl            | 0.015262497 |\n|    clip_fraction        | 0.127       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.474      |\n|    explained_variance   | -2.24e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 55.4        |\n|    n_updates            | 990         |\n|    policy_gradient_loss | 0.016       |\n|    value_loss           | 116         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 52.8        |\n| time/                   |             |\n|    fps                  | 2041        |\n|    iterations           | 101         |\n|    time_elapsed         | 101         |\n|    total_timesteps      | 206848      |\n| train/                  |             |\n|    approx_kl            | 0.010855144 |\n|    clip_fraction        | 0.102       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.465      |\n|    explained_variance   | -4.27e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 42.6        |\n|    n_updates            | 1000        |\n|    policy_gradient_loss | 0.00833     |\n|    value_loss           | 111         |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 36.9       |\n| time/                   |            |\n|    fps                  | 2042       |\n|    iterations           | 102        |\n|    time_elapsed         | 102        |\n|    total_timesteps      | 208896     |\n| train/                  |            |\n|    approx_kl            | 0.09577713 |\n|    clip_fraction        | 0.113      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.459     |\n|    explained_variance   | -6.19e-05  |\n|    learning_rate        | 0.0003     |\n|    loss                 | 56.7       |\n|    n_updates            | 1010       |\n|    policy_gradient_loss | 0.0111     |\n|    value_loss           | 113        |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 21.5       |\n| time/                   |            |\n|    fps                  | 2042       |\n|    iterations           | 103        |\n|    time_elapsed         | 103        |\n|    total_timesteps      | 210944     |\n| train/                  |            |\n|    approx_kl            | 0.05365608 |\n|    clip_fraction        | 0.197      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.485     |\n|    explained_variance   | -6.76e-05  |\n|    learning_rate        | 0.0003     |\n|    loss                 | 45.7       |\n|    n_updates            | 1020       |\n|    policy_gradient_loss | -0.011     |\n|    value_loss           | 103        |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 19.5        |\n| time/                   |             |\n|    fps                  | 2043        |\n|    iterations           | 104         |\n|    time_elapsed         | 104         |\n|    total_timesteps      | 212992      |\n| train/                  |             |\n|    approx_kl            | 0.053885683 |\n|    clip_fraction        | 0.243       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.483      |\n|    explained_variance   | 0.00379     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 39.1        |\n|    n_updates            | 1030        |\n|    policy_gradient_loss | -0.0132     |\n|    value_loss           | 75.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 37.3        |\n| time/                   |             |\n|    fps                  | 2043        |\n|    iterations           | 105         |\n|    time_elapsed         | 105         |\n|    total_timesteps      | 215040      |\n| train/                  |             |\n|    approx_kl            | 0.067209005 |\n|    clip_fraction        | 0.155       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.435      |\n|    explained_variance   | 0.00349     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 31.9        |\n|    n_updates            | 1040        |\n|    policy_gradient_loss | 0.000181    |\n|    value_loss           | 58.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 52.6        |\n| time/                   |             |\n|    fps                  | 2043        |\n|    iterations           | 106         |\n|    time_elapsed         | 106         |\n|    total_timesteps      | 217088      |\n| train/                  |             |\n|    approx_kl            | 0.002754151 |\n|    clip_fraction        | 0.0754      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.352      |\n|    explained_variance   | 0.00106     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 36          |\n|    n_updates            | 1050        |\n|    policy_gradient_loss | 0.0106      |\n|    value_loss           | 64.5        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 56.5        |\n| time/                   |             |\n|    fps                  | 2043        |\n|    iterations           | 107         |\n|    time_elapsed         | 107         |\n|    total_timesteps      | 219136      |\n| train/                  |             |\n|    approx_kl            | 0.012916878 |\n|    clip_fraction        | 0.0569      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.379      |\n|    explained_variance   | 7.99e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 32.4        |\n|    n_updates            | 1060        |\n|    policy_gradient_loss | 0.00575     |\n|    value_loss           | 82.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 55.7        |\n| time/                   |             |\n|    fps                  | 2044        |\n|    iterations           | 108         |\n|    time_elapsed         | 108         |\n|    total_timesteps      | 221184      |\n| train/                  |             |\n|    approx_kl            | 0.028656289 |\n|    clip_fraction        | 0.109       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.367      |\n|    explained_variance   | 1.13e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 63.7        |\n|    n_updates            | 1070        |\n|    policy_gradient_loss | 0.0151      |\n|    value_loss           | 96.4        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 54.4        |\n| time/                   |             |\n|    fps                  | 2043        |\n|    iterations           | 109         |\n|    time_elapsed         | 109         |\n|    total_timesteps      | 223232      |\n| train/                  |             |\n|    approx_kl            | 0.003285658 |\n|    clip_fraction        | 0.0652      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.346      |\n|    explained_variance   | -9.97e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 54.3        |\n|    n_updates            | 1080        |\n|    policy_gradient_loss | 0.00573     |\n|    value_loss           | 105         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 54          |\n| time/                   |             |\n|    fps                  | 2043        |\n|    iterations           | 110         |\n|    time_elapsed         | 110         |\n|    total_timesteps      | 225280      |\n| train/                  |             |\n|    approx_kl            | 0.022203729 |\n|    clip_fraction        | 0.088       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.367      |\n|    explained_variance   | -7.82e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 46.7        |\n|    n_updates            | 1090        |\n|    policy_gradient_loss | 0.0128      |\n|    value_loss           | 109         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 53.9        |\n| time/                   |             |\n|    fps                  | 2043        |\n|    iterations           | 111         |\n|    time_elapsed         | 111         |\n|    total_timesteps      | 227328      |\n| train/                  |             |\n|    approx_kl            | 0.017038612 |\n|    clip_fraction        | 0.0849      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.361      |\n|    explained_variance   | -1.63e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 31.3        |\n|    n_updates            | 1100        |\n|    policy_gradient_loss | 0.00982     |\n|    value_loss           | 106         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 54.4         |\n| time/                   |              |\n|    fps                  | 2043         |\n|    iterations           | 112          |\n|    time_elapsed         | 112          |\n|    total_timesteps      | 229376       |\n| train/                  |              |\n|    approx_kl            | 0.0090918755 |\n|    clip_fraction        | 0.0701       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.326       |\n|    explained_variance   | -3.35e-05    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 52.9         |\n|    n_updates            | 1110         |\n|    policy_gradient_loss | 0.00839      |\n|    value_loss           | 113          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 52.4        |\n| time/                   |             |\n|    fps                  | 2044        |\n|    iterations           | 113         |\n|    time_elapsed         | 113         |\n|    total_timesteps      | 231424      |\n| train/                  |             |\n|    approx_kl            | 0.003149661 |\n|    clip_fraction        | 0.0779      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.358      |\n|    explained_variance   | -4.77e-07   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 62.4        |\n|    n_updates            | 1120        |\n|    policy_gradient_loss | 0.00909     |\n|    value_loss           | 108         |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | 49.8       |\n| time/                   |            |\n|    fps                  | 2044       |\n|    iterations           | 114        |\n|    time_elapsed         | 114        |\n|    total_timesteps      | 233472     |\n| train/                  |            |\n|    approx_kl            | 0.01342451 |\n|    clip_fraction        | 0.138      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.391     |\n|    explained_variance   | -7.01e-05  |\n|    learning_rate        | 0.0003     |\n|    loss                 | 71.2       |\n|    n_updates\n[too much output ...]"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/usr/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n  warnings.warn(\n"
                },
                {
                    "data": {
                        "text/plain": "(0.0, 60.0)"
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Define a path for where to output the training log files\n",
                "log_path = os.path.join('ReinforcementLearning/ShowerEnvironment/Training', 'Logs')\n",
                "\n",
                "# Set up model, pass in 'MlpPolicy' as the policy we use, \n",
                "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)\n",
                "\n",
                "# Start to train the model\n",
                "model.learn(total_timesteps=500000)\n",
                "\n",
                "#Save the model\n",
                "model.save('PPO')\n",
                "\n",
                "# Evaluate the model (with render set to false)\n",
                "evaluate_policy(model, env, n_eval_episodes=10, render=False)"
            ]
        }
    ]
}
