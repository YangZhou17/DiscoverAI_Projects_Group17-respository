{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **Custom Environment for Reinforcement Learning**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The code below is taken from Nicholas Renotte's tutorial on how to create Custom environments for reinforcement learning. [Tutorial](https://youtu.be/Mut_u40Sqz4?t=8940), [code on github](https://github.com/nicknochnack/ReinforcementLearningCourse/blob/main/Project%203%20-%20Custom%20Environment.ipynb).\n",
                "\n",
                "You are encouraged to visit the links above and check out the full code. In this lab, you will practice training a model."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**About the problem**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The task is to build an agent that regulates the shower temperature to give the best shower possible every time.\n",
                "\n",
                "Based the activity of other people in the building, the temperature fluctuates randomly. Assuming that our optimal temperature is between 37 and 39 degrees, we want to train an agent to automatically respond to changes in temperature and get it back within the preferred range.\n",
                "\n",
                "Note that the agent does not know the preffered range ahead of time, and should instead learn the types of adjustments it can make to get a reward."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Import libraries**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "# Avoid reinstalling packages that are available on edstem\n",
                "if not os.getenv(\"ED_COURSE_ID\"):\n",
                "    !pip install tensorflow stable_baselines3 torch collections gym box2d-py --user\n",
                "\n",
                "# Import gym libraries\n",
                "import gym \n",
                "from gym import Env # the supperclass to build our own environment\n",
                "# All different types of spaces available in Gym\n",
                "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete \n",
                "\n",
                "# Import helpers\n",
                "import numpy as np\n",
                "import random\n",
                "\n",
                "#Import stable bbaselines libraries\n",
                "from stable_baselines3 import PPO\n",
                "from stable_baselines3.common.vec_env import DummyVecEnv\n",
                "from stable_baselines3.common.evaluation import evaluate_policy"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Inspect types of spaces"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There are four key types of Gym spaces:\n",
                "Box, Discrete, Multibinary and MultiDiscrete.\n",
                "\n",
                "There are two wrapper spaces, Tuple and Dict that help group different spaces together.\n",
                "\n",
                "These spaces can be used to create simple environment, like the shower environment in the following example."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a discrete space\n",
                "disc = Discrete(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "1"
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Sample the discrete space for a value (between 0 and 2)\n",
                "disc.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a box space\n",
                "box = Box(0,1,shape=(3,3))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[0.15143314, 0.34911984, 0.43493873],\n       [0.03203558, 0.25423893, 0.34316856],\n       [0.95327836, 0.65670663, 0.742812  ]], dtype=float32)"
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Sample the box space for a value\n",
                "box.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a tuple space and combine a discrete and box spaces\n",
                "tup = Tuple((Discrete(2), Box(0,100, shape=(1,))))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(0, array([78.21167], dtype=float32))"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Sample the tuple space for a value\n",
                "tup.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a dict space\n",
                "dic = Dict({'height':Discrete(2), \"speed\":Box(0,100, shape=(1,))}).sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a multibinary space\n",
                "multibi = MultiBinary(4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 1, 1, 0], dtype=int8)"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Sample the multibinary space for a value\n",
                "multibi.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a multidiscrete space\n",
                "multidi = MultiDiscrete([5,2,2])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([0, 1, 1])"
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Sample the multidiscrete space for a value\n",
                "multidi.sample()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Create a custom environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a shower environment class with four key functions\n",
                "class ShowerEnv(Env):\n",
                "    # Define a function to initialize the environment\n",
                "    def __init__(self):\n",
                "        # Define the discrete action space: \n",
                "        # Actions we can take, down, hold, up\n",
                "        self.action_space = Discrete(3)\n",
                "        # Define a temperature range from 0 to 100\n",
                "        self.observation_space = Box(low=np.array([0]), high=np.array([100]))\n",
                "        # Set initial state: starting temp is 38 +- 3\n",
                "        self.state = 38 + random.randint(-3,3)\n",
                "        # Set shower length: set to 60 seconds for testing\n",
                "        self.shower_length = 60\n",
                "\n",
                "    # Define the step function for what to do in one action step    \n",
                "    def step(self, action):\n",
                "        # Apply impact of the action on current state\n",
                "        # 0 -1 = -1 temperature\n",
                "        # 1 -1 = 0 \n",
                "        # 2 -1 = 1 temperature \n",
                "        self.state += action -1 \n",
                "        # Reduce shower length by 1 second at each action\n",
                "        self.shower_length -= 1 \n",
                "        \n",
                "        # Calculate reward\n",
                "        # If the temperature is within preferred range, the reward is positive\n",
                "        if self.state \u003e= 37 and self.state \u003c= 39: \n",
                "            reward = 1 \n",
                "        # If the reward is outside of preferred range, the reward is negative \n",
                "        else: \n",
                "            reward = -1 \n",
                "        \n",
                "        # Check if shower is done\n",
                "        if self.shower_length \u003c= 0: \n",
                "            done = True\n",
                "        else:\n",
                "            done = False\n",
                "        \n",
                "        # Set placeholder for info\n",
                "        info = {}\n",
                "        \n",
                "        # Return step information\n",
                "        return self.state, reward, done, info\n",
                "\n",
                "    # For this lab, we will not implement a visualization of the environment\n",
                "    def render(self):\n",
                "        # Implement viz\n",
                "        pass\n",
                "    \n",
                "    # Define function to reset the environment for the next run\n",
                "    def reset(self):\n",
                "        # Reset shower temperature to a random value between 35 and 41\n",
                "        self.state = np.array([38 + random.randint(-3,3)]).astype(float)\n",
                "        # Reset shower time\n",
                "        self.shower_length = 60 \n",
                "        return self.state"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Test the environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/usr/lib/python3.10/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
                }
            ],
            "source": [
                "# Initialize the environment\n",
                "env=ShowerEnv()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([38.61166], dtype=float32)"
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Write code to sample the environment's observation space\n",
                "env.observation_space.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "1"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#TODO: Write code to sample the environment's action space\n",
                "env.action_space.sample()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([39.])"
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Reset the environment\n",
                "env.reset()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Episode:1 Score:-20\nEpisode:2 Score:-24\nEpisode:3 Score:-56\nEpisode:4 Score:-52\nEpisode:5 Score:20\n"
                }
            ],
            "source": [
                "# Test five episodes of taking random Actions\n",
                "# in the environment\n",
                "episodes = 5\n",
                "for episode in range(1, episodes+1):\n",
                "    state = env.reset()\n",
                "    done = False\n",
                "    score = 0 \n",
                "    \n",
                "    while not done:\n",
                "        env.render()\n",
                "        action = env.action_space.sample()\n",
                "        n_state, reward, done, info = env.step(action)\n",
                "        score+=reward\n",
                "    print('Episode:{} Score:{}'.format(episode, score))\n",
                "    \n",
                "env.close()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Earn Your Wings"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Implement the rest of the reinforcement learning algorithm to train the model using MlpPolicy. Save the training in the log_path defined below, and evaluate the model at the end with render set to False. Add comments in your code to explain each step that you take in your implementation.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Using cpu device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\nLogging to ReinforcementLearning/ShowerEnvironment/Training/Logs/PPO_1\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 60       |\n|    ep_rew_mean     | -30.8    |\n| time/              |          |\n|    fps             | 1311     |\n|    iterations      | 1        |\n|    time_elapsed    | 1        |\n|    total_timesteps | 2048     |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -30.6       |\n| time/                   |             |\n|    fps                  | 1592        |\n|    iterations           | 2           |\n|    time_elapsed         | 2           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.012955134 |\n|    clip_fraction        | 0.117       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.09       |\n|    explained_variance   | -0.000821   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 24.3        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.00986    |\n|    value_loss           | 55.1        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -30.4       |\n| time/                   |             |\n|    fps                  | 1735        |\n|    iterations           | 3           |\n|    time_elapsed         | 3           |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.012879167 |\n|    clip_fraction        | 0.0678      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.09       |\n|    explained_variance   | -0.00759    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 27.5        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.00602    |\n|    value_loss           | 64          |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -30.4       |\n| time/                   |             |\n|    fps                  | 1814        |\n|    iterations           | 4           |\n|    time_elapsed         | 4           |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.012848634 |\n|    clip_fraction        | 0.0391      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.08       |\n|    explained_variance   | -0.000318   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 28.9        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.00301    |\n|    value_loss           | 64.2        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | -26.5      |\n| time/                   |            |\n|    fps                  | 1861       |\n|    iterations           | 5          |\n|    time_elapsed         | 5          |\n|    total_timesteps      | 10240      |\n| train/                  |            |\n|    approx_kl            | 0.00856679 |\n|    clip_fraction        | 0.0638     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.06      |\n|    explained_variance   | 6.3e-05    |\n|    learning_rate        | 0.0003     |\n|    loss                 | 33.9       |\n|    n_updates            | 40         |\n|    policy_gradient_loss | -0.00514   |\n|    value_loss           | 71.9       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -28         |\n| time/                   |             |\n|    fps                  | 1899        |\n|    iterations           | 6           |\n|    time_elapsed         | 6           |\n|    total_timesteps      | 12288       |\n| train/                  |             |\n|    approx_kl            | 0.005195644 |\n|    clip_fraction        | 0.00845     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.07       |\n|    explained_variance   | -0.000199   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 42.9        |\n|    n_updates            | 50          |\n|    policy_gradient_loss | -3.65e-05   |\n|    value_loss           | 86.4        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | -24.9      |\n| time/                   |            |\n|    fps                  | 1925       |\n|    iterations           | 7          |\n|    time_elapsed         | 7          |\n|    total_timesteps      | 14336      |\n| train/                  |            |\n|    approx_kl            | 0.01348839 |\n|    clip_fraction        | 0.036      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.05      |\n|    explained_variance   | 0.00106    |\n|    learning_rate        | 0.0003     |\n|    loss                 | 41         |\n|    n_updates            | 60         |\n|    policy_gradient_loss | -0.00396   |\n|    value_loss           | 69.2       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -26         |\n| time/                   |             |\n|    fps                  | 1949        |\n|    iterations           | 8           |\n|    time_elapsed         | 8           |\n|    total_timesteps      | 16384       |\n| train/                  |             |\n|    approx_kl            | 0.016446356 |\n|    clip_fraction        | 0.0294      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.998      |\n|    explained_variance   | -5.25e-06   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 51.6        |\n|    n_updates            | 70          |\n|    policy_gradient_loss | -0.000242   |\n|    value_loss           | 83.8        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -23.9        |\n| time/                   |              |\n|    fps                  | 1957         |\n|    iterations           | 9            |\n|    time_elapsed         | 9            |\n|    total_timesteps      | 18432        |\n| train/                  |              |\n|    approx_kl            | 0.0015393614 |\n|    clip_fraction        | 0.0288       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.903       |\n|    explained_variance   | 0.000561     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 42.3         |\n|    n_updates            | 80           |\n|    policy_gradient_loss | -0.000835    |\n|    value_loss           | 80.2         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -24.8       |\n| time/                   |             |\n|    fps                  | 1959        |\n|    iterations           | 10          |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 20480       |\n| train/                  |             |\n|    approx_kl            | 0.007379733 |\n|    clip_fraction        | 0.108       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.913      |\n|    explained_variance   | 0.00353     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 36.2        |\n|    n_updates            | 90          |\n|    policy_gradient_loss | -0.00679    |\n|    value_loss           | 76.3        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -25         |\n| time/                   |             |\n|    fps                  | 1967        |\n|    iterations           | 11          |\n|    time_elapsed         | 11          |\n|    total_timesteps      | 22528       |\n| train/                  |             |\n|    approx_kl            | 0.011337752 |\n|    clip_fraction        | 0.0348      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.867      |\n|    explained_variance   | 0.00282     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 47.5        |\n|    n_updates            | 100         |\n|    policy_gradient_loss | -0.00132    |\n|    value_loss           | 80.5        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -22          |\n| time/                   |              |\n|    fps                  | 1965         |\n|    iterations           | 12           |\n|    time_elapsed         | 12           |\n|    total_timesteps      | 24576        |\n| train/                  |              |\n|    approx_kl            | 0.0070722345 |\n|    clip_fraction        | 0.027        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.785       |\n|    explained_variance   | -0.00465     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 41.7         |\n|    n_updates            | 110          |\n|    policy_gradient_loss | -0.000578    |\n|    value_loss           | 90.6         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -21.5       |\n| time/                   |             |\n|    fps                  | 1976        |\n|    iterations           | 13          |\n|    time_elapsed         | 13          |\n|    total_timesteps      | 26624       |\n| train/                  |             |\n|    approx_kl            | 0.002717447 |\n|    clip_fraction        | 0.0331      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.76       |\n|    explained_variance   | 0.000404    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 57          |\n|    n_updates            | 120         |\n|    policy_gradient_loss | -0.000795   |\n|    value_loss           | 97.1        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -20.4       |\n| time/                   |             |\n|    fps                  | 1979        |\n|    iterations           | 14          |\n|    time_elapsed         | 14          |\n|    total_timesteps      | 28672       |\n| train/                  |             |\n|    approx_kl            | 0.008828074 |\n|    clip_fraction        | 0.0993      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.716      |\n|    explained_variance   | 0.00144     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 34.1        |\n|    n_updates            | 130         |\n|    policy_gradient_loss | -0.00388    |\n|    value_loss           | 96.8        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -16          |\n| time/                   |              |\n|    fps                  | 1987         |\n|    iterations           | 15           |\n|    time_elapsed         | 15           |\n|    total_timesteps      | 30720        |\n| train/                  |              |\n|    approx_kl            | 0.0028253596 |\n|    clip_fraction        | 0.0356       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.645       |\n|    explained_variance   | -0.00105     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 48.5         |\n|    n_updates            | 140          |\n|    policy_gradient_loss | -0.00279     |\n|    value_loss           | 85.9         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -10          |\n| time/                   |              |\n|    fps                  | 1994         |\n|    iterations           | 16           |\n|    time_elapsed         | 16           |\n|    total_timesteps      | 32768        |\n| train/                  |              |\n|    approx_kl            | 0.0037904847 |\n|    clip_fraction        | 0.0362       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.652       |\n|    explained_variance   | 0.000291     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 38.7         |\n|    n_updates            | 150          |\n|    policy_gradient_loss | -0.00251     |\n|    value_loss           | 97.2         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -5.22        |\n| time/                   |              |\n|    fps                  | 1998         |\n|    iterations           | 17           |\n|    time_elapsed         | 17           |\n|    total_timesteps      | 34816        |\n| train/                  |              |\n|    approx_kl            | 0.0028348342 |\n|    clip_fraction        | 0.0235       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.598       |\n|    explained_variance   | 0.000434     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 40.8         |\n|    n_updates            | 160          |\n|    policy_gradient_loss | -0.000447    |\n|    value_loss           | 86.3         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -12.1        |\n| time/                   |              |\n|    fps                  | 2003         |\n|    iterations           | 18           |\n|    time_elapsed         | 18           |\n|    total_timesteps      | 36864        |\n| train/                  |              |\n|    approx_kl            | 0.0011145994 |\n|    clip_fraction        | 0.0159       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.599       |\n|    explained_variance   | 0.00101      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 47.4         |\n|    n_updates            | 170          |\n|    policy_gradient_loss | 0.000273     |\n|    value_loss           | 102          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -19.4        |\n| time/                   |              |\n|    fps                  | 2007         |\n|    iterations           | 19           |\n|    time_elapsed         | 19           |\n|    total_timesteps      | 38912        |\n| train/                  |              |\n|    approx_kl            | 0.0019793736 |\n|    clip_fraction        | 0.0197       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.645       |\n|    explained_variance   | -0.00305     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 37.3         |\n|    n_updates            | 180          |\n|    policy_gradient_loss | -0.00073     |\n|    value_loss           | 69.2         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -22.3        |\n| time/                   |              |\n|    fps                  | 2005         |\n|    iterations           | 20           |\n|    time_elapsed         | 20           |\n|    total_timesteps      | 40960        |\n| train/                  |              |\n|    approx_kl            | 0.0043949843 |\n|    clip_fraction        | 0.0503       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.655       |\n|    explained_variance   | 0.0223       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 35.8         |\n|    n_updates            | 190          |\n|    policy_gradient_loss | -0.00332     |\n|    value_loss           | 76.8         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -17.3        |\n| time/                   |              |\n|    fps                  | 2007         |\n|    iterations           | 21           |\n|    time_elapsed         | 21           |\n|    total_timesteps      | 43008        |\n| train/                  |              |\n|    approx_kl            | 0.0035990654 |\n|    clip_fraction        | 0.0206       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.683       |\n|    explained_variance   | -0.00712     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 58.9         |\n|    n_updates            | 200          |\n|    policy_gradient_loss | -0.00151     |\n|    value_loss           | 113          |\n------------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | -11.3      |\n| time/                   |            |\n|    fps                  | 2008       |\n|    iterations           | 22         |\n|    time_elapsed         | 22         |\n|    total_timesteps      | 45056      |\n| train/                  |            |\n|    approx_kl            | 0.00471686 |\n|    clip_fraction        | 0.0672     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.624     |\n|    explained_variance   | 0.00807    |\n|    learning_rate        | 0.0003     |\n|    loss                 | 52.8       |\n|    n_updates            | 210        |\n|    policy_gradient_loss | -0.00678   |\n|    value_loss           | 94.6       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -10.9       |\n| time/                   |             |\n|    fps                  | 2012        |\n|    iterations           | 23          |\n|    time_elapsed         | 23          |\n|    total_timesteps      | 47104       |\n| train/                  |             |\n|    approx_kl            | 0.004974708 |\n|    clip_fraction        | 0.0189      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.56       |\n|    explained_variance   | 0.017       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 42.1        |\n|    n_updates            | 220         |\n|    policy_gradient_loss | -0.00168    |\n|    value_loss           | 105         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -13.5        |\n| time/                   |              |\n|    fps                  | 2012         |\n|    iterations           | 24           |\n|    time_elapsed         | 24           |\n|    total_timesteps      | 49152        |\n| train/                  |              |\n|    approx_kl            | 0.0005707716 |\n|    clip_fraction        | 0.0237       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.536       |\n|    explained_variance   | -0.0121      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 50.8         |\n|    n_updates            | 230          |\n|    policy_gradient_loss | -0.00116     |\n|    value_loss           | 112          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -12.2        |\n| time/                   |              |\n|    fps                  | 2016         |\n|    iterations           | 25           |\n|    time_elapsed         | 25           |\n|    total_timesteps      | 51200        |\n| train/                  |              |\n|    approx_kl            | 0.0011932664 |\n|    clip_fraction        | 0.0181       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.599       |\n|    explained_variance   | 0.00132      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 64.1         |\n|    n_updates            | 240          |\n|    policy_gradient_loss | -0.000448    |\n|    value_loss           | 98.3         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -17.2        |\n| time/                   |              |\n|    fps                  | 2017         |\n|    iterations           | 26           |\n|    time_elapsed         | 26           |\n|    total_timesteps      | 53248        |\n| train/                  |              |\n|    approx_kl            | 0.0023881728 |\n|    clip_fraction        | 0.0273       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.582       |\n|    explained_variance   | 0.02         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 37           |\n|    n_updates            | 250          |\n|    policy_gradient_loss | -0.00273     |\n|    value_loss           | 84.4         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -9.64       |\n| time/                   |             |\n|    fps                  | 2020        |\n|    iterations           | 27          |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 55296       |\n| train/                  |             |\n|    approx_kl            | 0.001888759 |\n|    clip_fraction        | 0.00654     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.544      |\n|    explained_variance   | -0.00713    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 57.9        |\n|    n_updates            | 260         |\n|    policy_gradient_loss | 0.000124    |\n|    value_loss           | 112         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -9.18        |\n| time/                   |              |\n|    fps                  | 2022         |\n|    iterations           | 28           |\n|    time_elapsed         | 28           |\n|    total_timesteps      | 57344        |\n| train/                  |              |\n|    approx_kl            | 0.0009741003 |\n|    clip_fraction        | 0.0253       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.504       |\n|    explained_variance   | 0.00494      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 49.4         |\n|    n_updates            | 270          |\n|    policy_gradient_loss | -0.00158     |\n|    value_loss           | 98.9         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -6.04        |\n| time/                   |              |\n|    fps                  | 2023         |\n|    iterations           | 29           |\n|    time_elapsed         | 29           |\n|    total_timesteps      | 59392        |\n| train/                  |              |\n|    approx_kl            | 0.0018936996 |\n|    clip_fraction        | 0.0342       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.516       |\n|    explained_variance   | -0.00999     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 58.6         |\n|    n_updates            | 280          |\n|    policy_gradient_loss | -0.0013      |\n|    value_loss           | 94.8         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -8.88        |\n| time/                   |              |\n|    fps                  | 2024         |\n|    iterations           | 30           |\n|    time_elapsed         | 30           |\n|    total_timesteps      | 61440        |\n| train/                  |              |\n|    approx_kl            | 0.0018958539 |\n|    clip_fraction        | 0.0122       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.507       |\n|    explained_variance   | 0.0122       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 47.8         |\n|    n_updates            | 290          |\n|    policy_gradient_loss | -0.000322    |\n|    value_loss           | 112          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -10.8        |\n| time/                   |              |\n|    fps                  | 2026         |\n|    iterations           | 31           |\n|    time_elapsed         | 31           |\n|    total_timesteps      | 63488        |\n| train/                  |              |\n|    approx_kl            | 0.0009116825 |\n|    clip_fraction        | 0.00513      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.479       |\n|    explained_variance   | 0.00105      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 47.6         |\n|    n_updates            | 300          |\n|    policy_gradient_loss | -0.000392    |\n|    value_loss           | 95.2         |\n------------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | -8.24         |\n| time/                   |               |\n|    fps                  | 2029          |\n|    iterations           | 32            |\n|    time_elapsed         | 32            |\n|    total_timesteps      | 65536         |\n| train/                  |               |\n|    approx_kl            | 0.00037730444 |\n|    clip_fraction        | 0.0243        |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.469        |\n|    explained_variance   | 0.0123        |\n|    learning_rate        | 0.0003        |\n|    loss                 | 46.6          |\n|    n_updates            | 310           |\n|    policy_gradient_loss | -0.00122      |\n|    value_loss           | 99.2          |\n-------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -8           |\n| time/                   |              |\n|    fps                  | 2029         |\n|    iterations           | 33           |\n|    time_elapsed         | 33           |\n|    total_timesteps      | 67584        |\n| train/                  |              |\n|    approx_kl            | 0.0025126706 |\n|    clip_fraction        | 0.0278       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.467       |\n|    explained_variance   | 0.0263       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 53.4         |\n|    n_updates            | 320          |\n|    policy_gradient_loss | -0.000733    |\n|    value_loss           | 114          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -7.68        |\n| time/                   |              |\n|    fps                  | 2032         |\n|    iterations           | 34           |\n|    time_elapsed         | 34           |\n|    total_timesteps      | 69632        |\n| train/                  |              |\n|    approx_kl            | 0.0055748606 |\n|    clip_fraction        | 0.0417       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.52        |\n|    explained_variance   | 0.0397       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 50.3         |\n|    n_updates            | 330          |\n|    policy_gradient_loss | 0.000168     |\n|    value_loss           | 97.5         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -10.9        |\n| time/                   |              |\n|    fps                  | 2034         |\n|    iterations           | 35           |\n|    time_elapsed         | 35           |\n|    total_timesteps      | 71680        |\n| train/                  |              |\n|    approx_kl            | 0.0020578066 |\n|    clip_fraction        | 0.0297       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.55        |\n|    explained_variance   | 0.0514       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 45.2         |\n|    n_updates            | 340          |\n|    policy_gradient_loss | -0.000447    |\n|    value_loss           | 88.4         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -10.4        |\n| time/                   |              |\n|    fps                  | 2036         |\n|    iterations           | 36           |\n|    time_elapsed         | 36           |\n|    total_timesteps      | 73728        |\n| train/                  |              |\n|    approx_kl            | 0.0016286348 |\n|    clip_fraction        | 0.031        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.561       |\n|    explained_variance   | -0.0483      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 63.1         |\n|    n_updates            | 350          |\n|    policy_gradient_loss | -0.00241     |\n|    value_loss           | 115          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -11.1        |\n| time/                   |              |\n|    fps                  | 2039         |\n|    iterations           | 37           |\n|    time_elapsed         | 37           |\n|    total_timesteps      | 75776        |\n| train/                  |              |\n|    approx_kl            | 0.0009113826 |\n|    clip_fraction        | 0.0215       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.586       |\n|    explained_variance   | 0.0227       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 59.9         |\n|    n_updates            | 360          |\n|    policy_gradient_loss | -0.000204    |\n|    value_loss           | 103          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -12.4        |\n| time/                   |              |\n|    fps                  | 2041         |\n|    iterations           | 38           |\n|    time_elapsed         | 38           |\n|    total_timesteps      | 77824        |\n| train/                  |              |\n|    approx_kl            | 0.0048318105 |\n|    clip_fraction        | 0.0588       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.59        |\n|    explained_variance   | 0.0121       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 38.5         |\n|    n_updates            | 370          |\n|    policy_gradient_loss | 0.000194     |\n|    value_loss           | 71.4         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -11.2        |\n| time/                   |              |\n|    fps                  | 2043         |\n|    iterations           | 39           |\n|    time_elapsed         | 39           |\n|    total_timesteps      | 79872        |\n| train/                  |              |\n|    approx_kl            | 0.0020862643 |\n|    clip_fraction        | 0.0462       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.535       |\n|    explained_variance   | 0.0781       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 42.2         |\n|    n_updates            | 380          |\n|    policy_gradient_loss | 2.59e-05     |\n|    value_loss           | 92.3         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -8.18        |\n| time/                   |              |\n|    fps                  | 2045         |\n|    iterations           | 40           |\n|    time_elapsed         | 40           |\n|    total_timesteps      | 81920        |\n| train/                  |              |\n|    approx_kl            | 0.0032784245 |\n|    clip_fraction        | 0.0548       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.536       |\n|    explained_variance   | -0.149       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 42.6         |\n|    n_updates            | 390          |\n|    policy_gradient_loss | -0.00259     |\n|    value_loss           | 85.4         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -4.7         |\n| time/                   |              |\n|    fps                  | 2047         |\n|    iterations           | 41           |\n|    time_elapsed         | 41           |\n|    total_timesteps      | 83968        |\n| train/                  |              |\n|    approx_kl            | 0.0022371588 |\n|    clip_fraction        | 0.0361       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.507       |\n|    explained_variance   | 0.0835       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 66.8         |\n|    n_updates            | 400          |\n|    policy_gradient_loss | -0.00194     |\n|    value_loss           | 102          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -6.98        |\n| time/                   |              |\n|    fps                  | 2049         |\n|    iterations           | 42           |\n|    time_elapsed         | 41           |\n|    total_timesteps      | 86016        |\n| train/                  |              |\n|    approx_kl            | 0.0023901812 |\n|    clip_fraction        | 0.0183       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.539       |\n|    explained_variance   | 0.0593       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 48.7         |\n|    n_updates            | 410          |\n|    policy_gradient_loss | -0.00109     |\n|    value_loss           | 111          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -5.22        |\n| time/                   |              |\n|    fps                  | 2051         |\n|    iterations           | 43           |\n|    time_elapsed         | 42           |\n|    total_timesteps      | 88064        |\n| train/                  |              |\n|    approx_kl            | 0.0028939527 |\n|    clip_fraction        | 0.0307       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.535       |\n|    explained_variance   | 0.108        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 40.3         |\n|    n_updates            | 420          |\n|    policy_gradient_loss | -0.000465    |\n|    value_loss           | 96.3         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -5.92        |\n| time/                   |              |\n|    fps                  | 2050         |\n|    iterations           | 44           |\n|    time_elapsed         | 43           |\n|    total_timesteps      | 90112        |\n| train/                  |              |\n|    approx_kl            | 0.0035372276 |\n|    clip_fraction        | 0.0208       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.538       |\n|    explained_variance   | 0.0523       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 39           |\n|    n_updates            | 430          |\n|    policy_gradient_loss | 0.000656     |\n|    value_loss           | 95.2         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -13.8       |\n| time/                   |             |\n|    fps                  | 2052        |\n|    iterations           | 45          |\n|    time_elapsed         | 44          |\n|    total_timesteps      | 92160       |\n| train/                  |             |\n|    approx_kl            | 0.003433006 |\n|    clip_fraction        | 0.0601      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.551      |\n|    explained_variance   | 0.124       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 40.7        |\n|    n_updates            | 440         |\n|    policy_gradient_loss | -0.00351    |\n|    value_loss           | 83.6        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -22.6        |\n| time/                   |              |\n|    fps                  | 2053         |\n|    iterations           | 46           |\n|    time_elapsed         | 45           |\n|    total_timesteps      | 94208        |\n| train/                  |              |\n|    approx_kl            | 0.0042346306 |\n|    clip_fraction        | 0.0816       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.553       |\n|    explained_variance   | 0.274        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 27.5         |\n|    n_updates            | 450          |\n|    policy_gradient_loss | -0.00518     |\n|    value_loss           | 64           |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -26.4        |\n| time/                   |              |\n|    fps                  | 2054         |\n|    iterations           | 47           |\n|    time_elapsed         | 46           |\n|    total_timesteps      | 96256        |\n| train/                  |              |\n|    approx_kl            | 0.0032863207 |\n|    clip_fraction        | 0.0853       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.508       |\n|    explained_variance   | 0.259        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 36           |\n|    n_updates            | 460          |\n|    policy_gradient_loss | -0.00529     |\n|    value_loss           | 88.4         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -17.7       |\n| time/                   |             |\n|    fps                  | 2055        |\n|    iterations           | 48          |\n|    time_elapsed         | 47          |\n|    total_timesteps      | 98304       |\n| train/                  |             |\n|    approx_kl            | 0.003235381 |\n|    clip_fraction        | 0.0612      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.516      |\n|    explained_variance   | 0.289       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 44.3        |\n|    n_updates            | 470         |\n|    policy_gradient_loss | -0.00294    |\n|    value_loss           | 90          |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -12.2        |\n| time/                   |              |\n|    fps                  | 2054         |\n|    iterations           | 49           |\n|    time_elapsed         | 48           |\n|    total_timesteps      | 100352       |\n| train/                  |              |\n|    approx_kl            | 0.0016550543 |\n|    clip_fraction        | 0.0723       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.509       |\n|    explained_variance   | 0.301        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 52.2         |\n|    n_updates            | 480          |\n|    policy_gradient_loss | -0.00751     |\n|    value_loss           | 105          |\n------------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | -3.88         |\n| time/                   |               |\n|    fps                  | 2055          |\n|    iterations           | 50            |\n|    time_elapsed         | 49            |\n|    total_timesteps      | 102400        |\n| train/                  |               |\n|    approx_kl            | 0.00016145021 |\n|    clip_fraction        | 0.00488       |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.499        |\n|    explained_variance   | 0.164         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 52.2          |\n|    n_updates            | 490           |\n|    policy_gradient_loss | 0.000249      |\n|    value_loss           | 102           |\n-------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -6.88        |\n| time/                   |              |\n|    fps                  | 2056         |\n|    iterations           | 51           |\n|    time_elapsed         | 50           |\n|    total_timesteps      | 104448       |\n| train/                  |              |\n|    approx_kl            | 0.0003063391 |\n|    clip_fraction        | 0.0222       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.489       |\n|    explained_variance   | 0.225        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 46.5         |\n|    n_updates            | 500          |\n|    policy_gradient_loss | -0.000742    |\n|    value_loss           | 110          |\n------------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | -6.9          |\n| time/                   |               |\n|    fps                  | 2057          |\n|    iterations           | 52            |\n|    time_elapsed         | 51            |\n|    total_timesteps      | 106496        |\n| train/                  |               |\n|    approx_kl            | 0.00043674742 |\n|    clip_fraction        | 0.00762       |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.479        |\n|    explained_variance   | 0.201         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 40.6          |\n|    n_updates            | 510           |\n|    policy_gradient_loss | -0.000174     |\n|    value_loss           | 89.2          |\n-------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -8.56       |\n| time/                   |             |\n|    fps                  | 2058        |\n|    iterations           | 53          |\n|    time_elapsed         | 52          |\n|    total_timesteps      | 108544      |\n| train/                  |             |\n|    approx_kl            | 0.002366547 |\n|    clip_fraction        | 0.0179      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.446      |\n|    explained_variance   | 0.26        |\n|    learning_rate        | 0.0003      |\n|    loss                 | 45.7        |\n|    n_updates            | 520         |\n|    policy_gradient_loss | -0.000176   |\n|    value_loss           | 94.1        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -5.9        |\n| time/                   |             |\n|    fps                  | 2059        |\n|    iterations           | 54          |\n|    time_elapsed         | 53          |\n|    total_timesteps      | 110592      |\n| train/                  |             |\n|    approx_kl            | 0.001207936 |\n|    clip_fraction        | 0.00625     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.414      |\n|    explained_variance   | 0.3         |\n|    learning_rate        | 0.0003      |\n|    loss                 | 40.7        |\n|    n_updates            | 530         |\n|    policy_gradient_loss | 6.96e-05    |\n|    value_loss           | 94.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -8.16       |\n| time/                   |             |\n|    fps                  | 2060        |\n|    iterations           | 55          |\n|    time_elapsed         | 54          |\n|    total_timesteps      | 112640      |\n| train/                  |             |\n|    approx_kl            | 0.002191369 |\n|    clip_fraction        | 0.00752     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.401      |\n|    explained_variance   | 0.3         |\n|    learning_rate        | 0.0003      |\n|    loss                 | 56.5        |\n|    n_updates            | 540         |\n|    policy_gradient_loss | 0.000188    |\n|    value_loss           | 96.4        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | -11.2      |\n| time/                   |            |\n|    fps                  | 2060       |\n|    iterations           | 56         |\n|    time_elapsed         | 55         |\n|    total_timesteps      | 114688     |\n| train/                  |            |\n|    approx_kl            | 0.12146283 |\n|    clip_fraction        | 0.0865     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.388     |\n|    explained_variance   | 0.341      |\n|    learning_rate        | 0.0003     |\n|    loss                 | 47.6       |\n|    n_updates            | 550        |\n|    policy_gradient_loss | 0.0112     |\n|    value_loss           | 83.6       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -13.4       |\n| time/                   |             |\n|    fps                  | 2060        |\n|    iterations           | 57          |\n|    time_elapsed         | 56          |\n|    total_timesteps      | 116736      |\n| train/                  |             |\n|    approx_kl            | 0.012678566 |\n|    clip_fraction        | 0.0159      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.225      |\n|    explained_variance   | 0.0705      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 41.3        |\n|    n_updates            | 560         |\n|    policy_gradient_loss | 0.00026     |\n|    value_loss           | 92.1        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -12          |\n| time/                   |              |\n|    fps                  | 2062         |\n|    iterations           | 58           |\n|    time_elapsed         | 57           |\n|    total_timesteps      | 118784       |\n| train/                  |              |\n|    approx_kl            | 0.0003493278 |\n|    clip_fraction        | 0.00493      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.23        |\n|    explained_variance   | 0.41         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 56           |\n|    n_updates            | 570          |\n|    policy_gradient_loss | -0.000272    |\n|    value_loss           | 108          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -6.06        |\n| time/                   |              |\n|    fps                  | 2062         |\n|    iterations           | 59           |\n|    time_elapsed         | 58           |\n|    total_timesteps      | 120832       |\n| train/                  |              |\n|    approx_kl            | 0.0006203884 |\n|    clip_fraction        | 0.0107       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.235       |\n|    explained_variance   | 0.399        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 58.6         |\n|    n_updates            | 580          |\n|    policy_gradient_loss | -0.000481    |\n|    value_loss           | 118          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -3.66        |\n| time/                   |              |\n|    fps                  | 2060         |\n|    iterations           | 60           |\n|    time_elapsed         | 59           |\n|    total_timesteps      | 122880       |\n| train/                  |              |\n|    approx_kl            | 0.0005742917 |\n|    clip_fraction        | 0.0166       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.238       |\n|    explained_variance   | 0.418        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 52           |\n|    n_updates            | 590          |\n|    policy_gradient_loss | -0.00167     |\n|    value_loss           | 112          |\n------------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | -2.9          |\n| time/                   |               |\n|    fps                  | 2061          |\n|    iterations           | 61            |\n|    time_elapsed         | 60            |\n|    total_timesteps      | 124928        |\n| train/                  |               |\n|    approx_kl            | 0.00019936197 |\n|    clip_fraction        | 0.0119        |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.228        |\n|    explained_variance   | 0.466         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 50.5          |\n|    n_updates            | 600           |\n|    policy_gradient_loss | -0.000786     |\n|    value_loss           | 108           |\n-------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 2.5          |\n| time/                   |              |\n|    fps                  | 2061         |\n|    iterations           | 62           |\n|    time_elapsed         | 61           |\n|    total_timesteps      | 126976       |\n| train/                  |              |\n|    approx_kl            | 0.0012434152 |\n|    clip_fraction        | 0.004        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.247       |\n|    explained_variance   | 0.476        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 45.6         |\n|    n_updates            | 610          |\n|    policy_gradient_loss | -0.000461    |\n|    value_loss           | 104          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 4.54         |\n| time/                   |              |\n|    fps                  | 2062         |\n|    iterations           | 63           |\n|    time_elapsed         | 62           |\n|    total_timesteps      | 129024       |\n| train/                  |              |\n|    approx_kl            | 0.0008106392 |\n|    clip_fraction        | 0.0121       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.286       |\n|    explained_variance   | 0.495        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 53.7         |\n|    n_updates            | 620          |\n|    policy_gradient_loss | -3.85e-05    |\n|    value_loss           | 105          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 7.02        |\n| time/                   |             |\n|    fps                  | 2063        |\n|    iterations           | 64          |\n|    time_elapsed         | 63          |\n|    total_timesteps      | 131072      |\n| train/                  |             |\n|    approx_kl            | 0.004361443 |\n|    clip_fraction        | 0.0388      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.285      |\n|    explained_variance   | 0.43        |\n|    learning_rate        | 0.0003      |\n|    loss                 | 33.8        |\n|    n_updates            | 630         |\n|    policy_gradient_loss | -0.00375    |\n|    value_loss           | 98.6        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 4.4          |\n| time/                   |              |\n|    fps                  | 2063         |\n|    iterations           | 65           |\n|    time_elapsed         | 64           |\n|    total_timesteps      | 133120       |\n| train/                  |              |\n|    approx_kl            | 0.0021585333 |\n|    clip_fraction        | 0.0184       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.293       |\n|    explained_variance   | 0.544        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 46.8         |\n|    n_updates            | 640          |\n|    policy_gradient_loss | 0.000939     |\n|    value_loss           | 96.9         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 2.8          |\n| time/                   |              |\n|    fps                  | 2064         |\n|    iterations           | 66           |\n|    time_elapsed         | 65           |\n|    total_timesteps      | 135168       |\n| train/                  |              |\n|    approx_kl            | 0.0018261914 |\n|    clip_fraction        | 0.024        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.264       |\n|    explained_variance   | 0.574        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 46.1         |\n|    n_updates            | 650          |\n|    policy_gradient_loss | 0.00128      |\n|    value_loss           | 97.6         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -0.9         |\n| time/                   |              |\n|    fps                  | 2064         |\n|    iterations           | 67           |\n|    time_elapsed         | 66           |\n|    total_timesteps      | 137216       |\n| train/                  |              |\n|    approx_kl            | 0.0006446764 |\n|    clip_fraction        | 0.0338       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.286       |\n|    explained_variance   | 0.55         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 58.6         |\n|    n_updates            | 660          |\n|    policy_gradient_loss | 0.0084       |\n|    value_loss           | 115          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -4.12        |\n| time/                   |              |\n|    fps                  | 2065         |\n|    iterations           | 68           |\n|    time_elapsed         | 67           |\n|    total_timesteps      | 139264       |\n| train/                  |              |\n|    approx_kl            | 0.0011828975 |\n|    clip_fraction        | 0.0255       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.3         |\n|    explained_variance   | 0.577        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 54.9         |\n|    n_updates            | 670          |\n|    policy_gradient_loss | -0.00186     |\n|    value_loss           | 113          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 0.46         |\n| time/                   |              |\n|    fps                  | 2066         |\n|    iterations           | 69           |\n|    time_elapsed         | 68           |\n|    total_timesteps      | 141312       |\n| train/                  |              |\n|    approx_kl            | 0.0014584122 |\n|    clip_fraction        | 0.0224       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.316       |\n|    explained_variance   | 0.582        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 36.6         |\n|    n_updates            | 680          |\n|    policy_gradient_loss | 0.000133     |\n|    value_loss           | 103          |\n------------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | -4.84      |\n| time/                   |            |\n|    fps                  | 2066       |\n|    iterations           | 70         |\n|    time_elapsed         | 69         |\n|    total_timesteps      | 143360     |\n| train/                  |            |\n|    approx_kl            | 0.00208116 |\n|    clip_fraction        | 0.0238     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.303     |\n|    explained_variance   | 0.557      |\n|    learning_rate        | 0.0003     |\n|    loss                 | 49         |\n|    n_updates            | 690        |\n|    policy_gradient_loss | -0.0011    |\n|    value_loss           | 97.5       |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 60         |\n|    ep_rew_mean          | -3         |\n| time/                   |            |\n|    fps                  | 2067       |\n|    iterations           | 71         |\n|    time_elapsed         | 70         |\n|    total_timesteps      | 145408     |\n| train/                  |            |\n|    approx_kl            | 0.00320401 |\n|    clip_fraction        | 0.0435     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.291     |\n|    explained_variance   | 0.474      |\n|    learning_rate        | 0.0003     |\n|    loss                 | 44.6       |\n|    n_updates            | 700        |\n|    policy_gradient_loss | 0.00182    |\n|    value_loss           | 101        |\n----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -2.48        |\n| time/                   |              |\n|    fps                  | 2068         |\n|    iterations           | 72           |\n|    time_elapsed         | 71           |\n|    total_timesteps      | 147456       |\n| train/                  |              |\n|    approx_kl            | 0.0014166931 |\n|    clip_fraction        | 0.0215       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.312       |\n|    explained_variance   | 0.583        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 42.4         |\n|    n_updates            | 710          |\n|    policy_gradient_loss | -6.96e-05    |\n|    value_loss           | 119          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 1.44         |\n| time/                   |              |\n|    fps                  | 2068         |\n|    iterations           | 73           |\n|    time_elapsed         | 72           |\n|    total_timesteps      | 149504       |\n| train/                  |              |\n|    approx_kl            | 0.0015229629 |\n|    clip_fraction        | 0.0286       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.303       |\n|    explained_variance   | 0.541        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 58.4         |\n|    n_updates            | 720          |\n|    policy_gradient_loss | 0.00125      |\n|    value_loss           | 112          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 0.3          |\n| time/                   |              |\n|    fps                  | 2068         |\n|    iterations           | 74           |\n|    time_elapsed         | 73           |\n|    total_timesteps      | 151552       |\n| train/                  |              |\n|    approx_kl            | 0.0011748454 |\n|    clip_fraction        | 0.0177       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.309       |\n|    explained_variance   | 0.593        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 50.8         |\n|    n_updates            | 730          |\n|    policy_gradient_loss | 0.000186     |\n|    value_loss           | 111          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -1.28        |\n| time/                   |              |\n|    fps                  | 2068         |\n|    iterations           | 75           |\n|    time_elapsed         | 74           |\n|    total_timesteps      | 153600       |\n| train/                  |              |\n|    approx_kl            | 0.0008019912 |\n|    clip_fraction        | 0.0124       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.309       |\n|    explained_variance   | 0.575        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 58.6         |\n|    n_updates            | 740          |\n|    policy_gradient_loss | 0.000538     |\n|    value_loss           | 117          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 3.54         |\n| time/                   |              |\n|    fps                  | 2068         |\n|    iterations           | 76           |\n|    time_elapsed         | 75           |\n|    total_timesteps      | 155648       |\n| train/                  |              |\n|    approx_kl            | 0.0019303402 |\n|    clip_fraction        | 0.0296       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.296       |\n|    explained_variance   | 0.577        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 71.6         |\n|    n_updates            | 750          |\n|    policy_gradient_loss | -0.00306     |\n|    value_loss           | 106          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 2.58         |\n| time/                   |              |\n|    fps                  | 2068         |\n|    iterations           | 77           |\n|    time_elapsed         | 76           |\n|    total_timesteps      | 157696       |\n| train/                  |              |\n|    approx_kl            | 0.0016606895 |\n|    clip_fraction        | 0.0281       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.282       |\n|    explained_variance   | 0.595        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 45.6         |\n|    n_updates            | 760          |\n|    policy_gradient_loss | 0.00285      |\n|    value_loss           | 113          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -0.1         |\n| time/                   |              |\n|    fps                  | 2069         |\n|    iterations           | 78           |\n|    time_elapsed         | 77           |\n|    total_timesteps      | 159744       |\n| train/                  |              |\n|    approx_kl            | 0.0018645038 |\n|    clip_fraction        | 0.024        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.276       |\n|    explained_variance   | 0.678        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 49           |\n|    n_updates            | 770          |\n|    policy_gradient_loss | 0.0024       |\n|    value_loss           | 100          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -4.8        |\n| time/                   |             |\n|    fps                  | 2069        |\n|    iterations           | 79          |\n|    time_elapsed         | 78          |\n|    total_timesteps      | 161792      |\n| train/                  |             |\n|    approx_kl            | 0.025065072 |\n|    clip_fraction        | 0.0314      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.265      |\n|    explained_variance   | 0.561       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 47.5        |\n|    n_updates            | 780         |\n|    policy_gradient_loss | 0.00937     |\n|    value_loss           | 126         |\n-----------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | 2.26          |\n| time/                   |               |\n|    fps                  | 2070          |\n|    iterations           | 80            |\n|    time_elapsed         | 79            |\n|    total_timesteps      | 163840        |\n| train/                  |               |\n|    approx_kl            | 0.00044555272 |\n|    clip_fraction        | 0.00903       |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.192        |\n|    explained_variance   | 0.66          |\n|    learning_rate        | 0.0003        |\n|    loss                 | 51.6          |\n|    n_updates            | 790           |\n|    policy_gradient_loss | 0.000183      |\n|    value_loss           | 110           |\n-------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 4.36         |\n| time/                   |              |\n|    fps                  | 2068         |\n|    iterations           | 81           |\n|    time_elapsed         | 80           |\n|    total_timesteps      | 165888       |\n| train/                  |              |\n|    approx_kl            | 0.0006864152 |\n|    clip_fraction        | 0.0164       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.159       |\n|    explained_variance   | 0.655        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 45.8         |\n|    n_updates            | 800          |\n|    policy_gradient_loss | 0.00161      |\n|    value_loss           | 105          |\n------------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | 1.22          |\n| time/                   |               |\n|    fps                  | 2068          |\n|    iterations           | 82            |\n|    time_elapsed         | 81            |\n|    total_timesteps      | 167936        |\n| train/                  |               |\n|    approx_kl            | 0.00022911918 |\n|    clip_fraction        | 0.00439       |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.148        |\n|    explained_variance   | 0.692         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 45.6          |\n|    n_updates            | 810           |\n|    policy_gradient_loss | -0.000338     |\n|    value_loss           | 110           |\n-------------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | -3.28         |\n| time/                   |               |\n|    fps                  | 2069          |\n|    iterations           | 83            |\n|    time_elapsed         | 82            |\n|    total_timesteps      | 169984        |\n| train/                  |               |\n|    approx_kl            | 0.00078982225 |\n|    clip_fraction        | 0.00518       |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.153        |\n|    explained_variance   | 0.669         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 46.1          |\n|    n_updates            | 820           |\n|    policy_gradient_loss | -0.000666     |\n|    value_loss           | 115           |\n-------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 1.16         |\n| time/                   |              |\n|    fps                  | 2069         |\n|    iterations           | 84           |\n|    time_elapsed         | 83           |\n|    total_timesteps      | 172032       |\n| train/                  |              |\n|    approx_kl            | 0.0012204906 |\n|    clip_fraction        | 0.0191       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.172       |\n|    explained_variance   | 0.694        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 49.5         |\n|    n_updates            | 830          |\n|    policy_gradient_loss | 0.00242      |\n|    value_loss           | 101          |\n------------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | 3.02          |\n| time/                   |               |\n|    fps                  | 2070          |\n|    iterations           | 85            |\n|    time_elapsed         | 84            |\n|    total_timesteps      | 174080        |\n| train/                  |               |\n|    approx_kl            | 9.5441384e-05 |\n|    clip_fraction        | 0.0109        |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.149        |\n|    explained_variance   | 0.692         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 56.2          |\n|    n_updates            | 840           |\n|    policy_gradient_loss | 0.000241      |\n|    value_loss           | 115           |\n-------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 2.86         |\n| time/                   |              |\n|    fps                  | 2069         |\n|    iterations           | 86           |\n|    time_elapsed         | 85           |\n|    total_timesteps      | 176128       |\n| train/                  |              |\n|    approx_kl            | 0.0021285852 |\n|    clip_fraction        | 0.0192       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.149       |\n|    explained_variance   | 0.702        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 45.9         |\n|    n_updates            | 850          |\n|    policy_gradient_loss | 0.000528     |\n|    value_loss           | 112          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 1.7          |\n| time/                   |              |\n|    fps                  | 2070         |\n|    iterations           | 87           |\n|    time_elapsed         | 86           |\n|    total_timesteps      | 178176       |\n| train/                  |              |\n|    approx_kl            | 0.0005897477 |\n|    clip_fraction        | 0.0172       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.175       |\n|    explained_variance   | 0.66         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 63.2         |\n|    n_updates            | 860          |\n|    policy_gradient_loss | -0.00394     |\n|    value_loss           | 109          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 4.5          |\n| time/                   |              |\n|    fps                  | 2070         |\n|    iterations           | 88           |\n|    time_elapsed         | 87           |\n|    total_timesteps      | 180224       |\n| train/                  |              |\n|    approx_kl            | 0.0067852773 |\n|    clip_fraction        | 0.0203       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.178       |\n|    explained_variance   | 0.711        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 62.4         |\n|    n_updates            | 870          |\n|    policy_gradient_loss | 0.00384      |\n|    value_loss           | 113          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 1.02        |\n| time/                   |             |\n|    fps                  | 2071        |\n|    iterations           | 89          |\n|    time_elapsed         | 87          |\n|    total_timesteps      | 182272      |\n| train/                  |             |\n|    approx_kl            | 0.018948622 |\n|    clip_fraction        | 0.0202      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.139      |\n|    explained_variance   | 0.725       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 64.5        |\n|    n_updates            | 880         |\n|    policy_gradient_loss | 0.00585     |\n|    value_loss           | 116         |\n-----------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | -5.06         |\n| time/                   |               |\n|    fps                  | 2071          |\n|    iterations           | 90            |\n|    time_elapsed         | 88            |\n|    total_timesteps      | 184320        |\n| train/                  |               |\n|    approx_kl            | 1.9856176e-05 |\n|    clip_fraction        | 0.0103        |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.107        |\n|    explained_variance   | 0.721         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 75.8          |\n|    n_updates            | 890           |\n|    policy_gradient_loss | 7.85e-05      |\n|    value_loss           | 115           |\n-------------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | -10.9         |\n| time/                   |               |\n|    fps                  | 2069          |\n|    iterations           | 91            |\n|    time_elapsed         | 90            |\n|    total_timesteps      | 186368        |\n| train/                  |               |\n|    approx_kl            | 0.00016414266 |\n|    clip_fraction        | 0.00674       |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.112        |\n|    explained_variance   | 0.697         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 60.6          |\n|    n_updates            | 900           |\n|    policy_gradient_loss | -0.00105      |\n|    value_loss           | 114           |\n-------------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | -10.7         |\n| time/                   |               |\n|    fps                  | 2068          |\n|    iterations           | 92            |\n|    time_elapsed         | 91            |\n|    total_timesteps      | 188416        |\n| train/                  |               |\n|    approx_kl            | 0.00067254633 |\n|    clip_fraction        | 0.00811       |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.105        |\n|    explained_variance   | 0.74          |\n|    learning_rate        | 0.0003        |\n|    loss                 | 58.3          |\n|    n_updates            | 910           |\n|    policy_gradient_loss | -0.00176      |\n|    value_loss           | 115           |\n-------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -8.72       |\n| time/                   |             |\n|    fps                  | 2068        |\n|    iterations           | 93          |\n|    time_elapsed         | 92          |\n|    total_timesteps      | 190464      |\n| train/                  |             |\n|    approx_kl            | 0.025040153 |\n|    clip_fraction        | 0.0104      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.125      |\n|    explained_variance   | 0.716       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 60.8        |\n|    n_updates            | 920         |\n|    policy_gradient_loss | 0.00357     |\n|    value_loss           | 122         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -0.16        |\n| time/                   |              |\n|    fps                  | 2068         |\n|    iterations           | 94           |\n|    time_elapsed         | 93           |\n|    total_timesteps      | 192512       |\n| train/                  |              |\n|    approx_kl            | 0.0032971906 |\n|    clip_fraction        | 0.0208       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.128       |\n|    explained_variance   | 0.764        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 50.8         |\n|    n_updates            | 930          |\n|    policy_gradient_loss | 0.0039       |\n|    value_loss           | 120          |\n------------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | 5.56          |\n| time/                   |               |\n|    fps                  | 2069          |\n|    iterations           | 95            |\n|    time_elapsed         | 94            |\n|    total_timesteps      | 194560        |\n| train/                  |               |\n|    approx_kl            | 0.00054927927 |\n|    clip_fraction        | 0.0162        |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.125        |\n|    explained_variance   | 0.781         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 60.7          |\n|    n_updates            | 940           |\n|    policy_gradient_loss | -0.00109      |\n|    value_loss           | 121           |\n-------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 6.38        |\n| time/                   |             |\n|    fps                  | 2069        |\n|    iterations           | 96          |\n|    time_elapsed         | 94          |\n|    total_timesteps      | 196608      |\n| train/                  |             |\n|    approx_kl            | 0.052534252 |\n|    clip_fraction        | 0.0222      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.172      |\n|    explained_variance   | 0.774       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 58.4        |\n|    n_updates            | 950         |\n|    policy_gradient_loss | 0.0133      |\n|    value_loss           | 117         |\n-----------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | 1.12          |\n| time/                   |               |\n|    fps                  | 2069          |\n|    iterations           | 97            |\n|    time_elapsed         | 95            |\n|    total_timesteps      | 198656        |\n| train/                  |               |\n|    approx_kl            | 0.00036382177 |\n|    clip_fraction        | 0.00801       |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.151        |\n|    explained_variance   | 0.654         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 44.5          |\n|    n_updates            | 960           |\n|    policy_gradient_loss | 0.000276      |\n|    value_loss           | 128           |\n-------------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | -0.2          |\n| time/                   |               |\n|    fps                  | 2070          |\n|    iterations           | 98            |\n|    time_elapsed         | 96            |\n|    total_timesteps      | 200704        |\n| train/                  |               |\n|    approx_kl            | 0.00092995306 |\n|    clip_fraction        | 0.0143        |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.148        |\n|    explained_variance   | 0.665         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 62.1          |\n|    n_updates            | 970           |\n|    policy_gradient_loss | -0.00154      |\n|    value_loss           | 118           |\n-------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -6.34        |\n| time/                   |              |\n|    fps                  | 2070         |\n|    iterations           | 99           |\n|    time_elapsed         | 97           |\n|    total_timesteps      | 202752       |\n| train/                  |              |\n|    approx_kl            | 0.0013412521 |\n|    clip_fraction        | 0.0252       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.129       |\n|    explained_variance   | 0.664        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 62           |\n|    n_updates            | 980          |\n|    policy_gradient_loss | -0.00286     |\n|    value_loss           | 142          |\n------------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | -4.98         |\n| time/                   |               |\n|    fps                  | 2071          |\n|    iterations           | 100           |\n|    time_elapsed         | 98            |\n|    total_timesteps      | 204800        |\n| train/                  |               |\n|    approx_kl            | 0.00062480953 |\n|    clip_fraction        | 0.0159        |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.156        |\n|    explained_variance   | 0.736         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 42.5          |\n|    n_updates            | 990           |\n|    policy_gradient_loss | 0.0056        |\n|    value_loss           | 128           |\n-------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -5.32        |\n| time/                   |              |\n|    fps                  | 2071         |\n|    iterations           | 101          |\n|    time_elapsed         | 99           |\n|    total_timesteps      | 206848       |\n| train/                  |              |\n|    approx_kl            | 0.0006512323 |\n|    clip_fraction        | 0.0115       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.133       |\n|    explained_variance   | 0.777        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 66.7         |\n|    n_updates            | 1000         |\n|    policy_gradient_loss | -0.000732    |\n|    value_loss           | 114          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | 3.5         |\n| time/                   |             |\n|    fps                  | 2070        |\n|    iterations           | 102         |\n|    time_elapsed         | 100         |\n|    total_timesteps      | 208896      |\n| train/                  |             |\n|    approx_kl            | 0.000390189 |\n|    clip_fraction        | 0.0041      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.139      |\n|    explained_variance   | 0.717       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 58.3        |\n|    n_updates            | 1010        |\n|    policy_gradient_loss | 0.000554    |\n|    value_loss           | 124         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 7.68         |\n| time/                   |              |\n|    fps                  | 2071         |\n|    iterations           | 103          |\n|    time_elapsed         | 101          |\n|    total_timesteps      | 210944       |\n| train/                  |              |\n|    approx_kl            | 0.0008109171 |\n|    clip_fraction        | 0.0209       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.126       |\n|    explained_variance   | 0.758        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 58.5         |\n|    n_updates            | 1020         |\n|    policy_gradient_loss | -0.00047     |\n|    value_loss           | 104          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 7.54         |\n| time/                   |              |\n|    fps                  | 2072         |\n|    iterations           | 104          |\n|    time_elapsed         | 102          |\n|    total_timesteps      | 212992       |\n| train/                  |              |\n|    approx_kl            | 0.0014485135 |\n|    clip_fraction        | 0.0154       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.127       |\n|    explained_variance   | 0.761        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 48.4         |\n|    n_updates            | 1030         |\n|    policy_gradient_loss | 0.000119     |\n|    value_loss           | 108          |\n------------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | 2.3           |\n| time/                   |               |\n|    fps                  | 2072          |\n|    iterations           | 105           |\n|    time_elapsed         | 103           |\n|    total_timesteps      | 215040        |\n| train/                  |               |\n|    approx_kl            | 0.00020510625 |\n|    clip_fraction        | 0.00776       |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.127        |\n|    explained_variance   | 0.755         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 53.3          |\n|    n_updates            | 1040          |\n|    policy_gradient_loss | -0.000552     |\n|    value_loss           | 114           |\n-------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 4.6          |\n| time/                   |              |\n|    fps                  | 2073         |\n|    iterations           | 106          |\n|    time_elapsed         | 104          |\n|    total_timesteps      | 217088       |\n| train/                  |              |\n|    approx_kl            | 0.0010078844 |\n|    clip_fraction        | 0.00957      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.127       |\n|    explained_variance   | 0.795        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 61           |\n|    n_updates            | 1050         |\n|    policy_gradient_loss | 0.000688     |\n|    value_loss           | 112          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | 0.56         |\n| time/                   |              |\n|    fps                  | 2073         |\n|    iterations           | 107          |\n|    time_elapsed         | 105          |\n|    total_timesteps      | 219136       |\n| train/                  |              |\n|    approx_kl            | 0.0006199272 |\n|    clip_fraction        | 0.0105       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.119       |\n|    explained_variance   | 0.744        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 74.3         |\n|    n_updates            | 1060         |\n|    policy_gradient_loss | -0.00166     |\n|    value_loss           | 127          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -2.28        |\n| time/                   |              |\n|    fps                  | 2073         |\n|    iterations           | 108          |\n|    time_elapsed         | 106          |\n|    total_timesteps      | 221184       |\n| train/                  |              |\n|    approx_kl            | 0.0020602238 |\n|    clip_fraction        | 0.0118       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.106       |\n|    explained_variance   | 0.779        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 49.5         |\n|    n_updates            | 1070         |\n|    policy_gradient_loss | 0.00338      |\n|    value_loss           | 115          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 60          |\n|    ep_rew_mean          | -8.38       |\n| time/                   |             |\n|    fps                  | 2073        |\n|    iterations           | 109         |\n|    time_elapsed         | 107         |\n|    total_timesteps      | 223232      |\n| train/                  |             |\n|    approx_kl            | 0.089141905 |\n|    clip_fraction        | 0.0109      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.126      |\n|    explained_variance   | 0.687       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 48.8        |\n|    n_updates            | 1080        |\n|    policy_gradient_loss | 0.00711     |\n|    value_loss           | 118         |\n-----------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 60            |\n|    ep_rew_mean          | -7.42         |\n| time/                   |               |\n|    fps                  | 2074          |\n|    iterations           | 110           |\n|    time_elapsed         | 108           |\n|    total_timesteps      | 225280        |\n| train/                  |               |\n|    approx_kl            | 0.00038648277 |\n|    clip_fraction        | 0.0296        |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.194        |\n|    explained_variance   | 0.575         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 69.4          |\n|    n_updates            | 1090          |\n|    policy_gradient_loss | -0.0006       |\n|    value_loss           | 171           |\n-------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -6.62        |\n| time/                   |              |\n|    fps                  | 2074         |\n|    iterations           | 111          |\n|    time_elapsed         | 109          |\n|    total_timesteps      | 227328       |\n| train/                  |              |\n|    approx_kl            | 0.0010418013 |\n|    clip_fraction        | 0.0201       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.185       |\n|    explained_variance   | 0.674        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 68.9         |\n|    n_updates            | 1100         |\n|    policy_gradient_loss | 0.000156     |\n|    value_loss           | 137          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 60           |\n|    ep_rew_mean          | -6.26        |\n| time/                   |              |\n|    fps                  | 2075         |\n|    iterations           | 112          |\n|    time_elapsed         | 110          |\n|    total_timesteps      | 229376       |\n| train/                  |              |\n|    approx_kl            | 0.0025458415 |\n|    clip_fraction        | 0.0257       |\n|    clip_range           | 0.2          |\n|    \n[too much output ...]"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/usr/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n  warnings.warn(\n"
                },
                {
                    "data": {
                        "text/plain": "(-12.0, 58.787753826796276)"
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Define a path for where to output the training log files\n",
                "log_path = os.path.join('ReinforcementLearning/ShowerEnvironment/Training', 'Logs')\n",
                "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_path)\n",
                "model.learn(total_timesteps=400000)\n",
                "model.save('PPO')\n",
                "evaluate_policy(model, env, n_eval_episodes=10, render=False)"
            ]
        }
    ]
}
